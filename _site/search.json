[
  {
    "objectID": "riddlers.html",
    "href": "riddlers.html",
    "title": "Puzzles Archive",
    "section": "",
    "text": "I really like puzzles! The Riddler (now The Fiddler) gives me a chance to explore something new each week — sometimes analytically, sometimes computationally, sometimes artistically.\nBelow is a collection of my solutions, spanning the FiveThirtyEight era and beyond."
  },
  {
    "objectID": "riddlers.html#section",
    "href": "riddlers.html#section",
    "title": "Puzzles Archive",
    "section": "2023",
    "text": "2023\n\n\n\n\nDate\nPuzzle\nMy Solution\nCode\n\n\n\n\nJan 27\nFive-letter guessing game\nblog\n—\n\n\nJan 23\nDrone vs. scooter metric\nblog\n—"
  },
  {
    "objectID": "riddlers.html#section-1",
    "href": "riddlers.html#section-1",
    "title": "Puzzles Archive",
    "section": "2022",
    "text": "2022\n\n\n\n\nDate\nPuzzle\nMy Solution\nCode\n\n\n\n\nDec 16\nGift exchange chaos\nblog\n—\n\n\nOct 21\nMexican Lottery\nblog\n—\n\n\nOct 14\nBirthday collisions\nblog\n—\n\n\nSept 16\nLongest anigram\nblog\n—\n\n\nSept 9\nCookie sheet packing\nblog\n—\n\n\nJuly 1\nTwo Astronomers’ Towers\nPDF\n—\n\n\nJune 24\nGoat tower parking\nPDF\n—\n\n\nJune 17\nElevensies / urn probabilities\nPDF\n—\n\n\nMay 13\nNonconformist dice\nPDF\n—\n\n\nJan 7\nTriangle trek\nPDF\n—"
  },
  {
    "objectID": "riddlers.html#section-2",
    "href": "riddlers.html#section-2",
    "title": "Puzzles Archive",
    "section": "2021",
    "text": "2021\n\n\n\n\nDate\nPuzzle\nMy Solution\nCode\n\n\n\n\nApr 23\nRandom voting\nPDF\n—\n\n\nApr 16\nLunar phase speed\nPDF\n—\n\n\nApr 9\nOne-way out\nPDF\ncode\n\n\nApr 2\nOutthink the Sphinx\nPDF\n—\n\n\nMar 26\nMarch Mathness\nPDF\n—\n\n\nMar 19\nSquare residues mod 10\nPDF\n—\n\n\nMar 12\nBiggest pie\nPDF\n—\n\n\nMar 5\nBatting .299\nPDF\n—\n\n\nFeb 19\nRiddler Jenga\n(link coming)\n—\n\n\nDec 13\nFencing Relay\nPDF\n—"
  },
  {
    "objectID": "riddlers.html#older-solutions",
    "href": "riddlers.html#older-solutions",
    "title": "Puzzles Archive",
    "section": "Older Solutions",
    "text": "Older Solutions\nSome earlier solutions are still available at my old site. Others may eventually be added here as I find time to polish them."
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Download CV (PDF)\nYou can also embed a short summary here or link to Google Scholar, ORCID, etc."
  },
  {
    "objectID": "blog/posts/2023-01-23-riddler-drone-metric.html",
    "href": "blog/posts/2023-01-23-riddler-drone-metric.html",
    "title": "Riddler: As the drone flies — Can you make a speedy delivery?",
    "section": "",
    "text": "My solution to this week’s riddler. (See more of my Riddler solutions here.)"
  },
  {
    "objectID": "blog/posts/2023-01-23-riddler-drone-metric.html#the-problem",
    "href": "blog/posts/2023-01-23-riddler-drone-metric.html#the-problem",
    "title": "Riddler: As the drone flies — Can you make a speedy delivery?",
    "section": "The Problem",
    "text": "The Problem\nFrom Graydon Snider comes a dilemma of delivery:\n\nA restaurant at the center of Riddler City is testing an airborne drone delivery service against their existing fleet of scooters. The restaurant is at the center of a large Manhattan-like array of square city blocks, which the scooter must follow.\nBoth vehicles travel at the same speed, which means drones can make more deliveries per unit time. Assume that (1) Riddler City is circular in shape, as you may recall (2) deliveries are made to random locations throughout the city and (3) the city is much, much larger than its individual blocks.\nIn a given amount of time, what is the expected ratio between the number of deliveries a drone can make to the number of deliveries a scooter can make?\nExtra credit: In addition to traveling parallel to the city blocks, suppose scooters can also move diagonally from one corner of a block to the opposite corner of the block. Now, what is the new expected ratio between the number of deliveries a drone can make and the number of deliveries a scooter can make?\n\n\nSolution\nLet the radius of Riddler City be equal to 1, so that the extent of the city is simply the unit disc. As indicated in the (non-extra-credit) problem statement, the scooter travels according to the taxicab metric (also known as the Manhattan distance). To solve this problem, we need to compute the expected distance that the drone and scooter will travel given a randomly chosen point in the City.\nThe amount of time a delivery takes is proportional to its distance, and the expected number of deliveries that can be made in a given amount of time is proportional to the inverse of the average time. So the ratio of the expected numbers of deliveries is equal to the inverse of the ratio of the expected distances.\n\nAs the drone flies\nWe first consider the drone, which always takes the most direct route by flying in a straight line. Using polar coordinates \\(r\\in[0,1]\\) and \\(\\theta\\in[0,2\\pi)\\) to parameterize the disc, the distance to a point from the origin is just the radial distance \\(r\\). The desired expected value is simply the average of \\(r\\) over the disc divided by the total area (which is equal to π). The area element for this integral is \\(\\operatorname{d} \\mspace{-1mu}A=r\\,\\operatorname{d} \\mspace{-1mu}r\\,\\operatorname{d} \\mspace{-1mu}\\theta\\), so to compute the expected distance that the drone travels, we have\n\\[\n\\begin{align*}\nE_{\\text{drone}}\n&= \\frac{1}{\\pi}\\int_{\\text{City}}r\\, \\operatorname{d} \\mspace{-1mu}A\\\\\n&= \\frac{1}{\\pi}\\int_0^{2\\pi}\\int_0^1r^2\\, \\operatorname{d} \\mspace{-1mu}r\\,\\operatorname{d} \\mspace{-1mu}\\theta\\\\\n&= \\frac{1}{\\pi}(2\\pi)\\frac{1}{3}\\\\\n& = \\frac{2}{3},\n\\end{align*}\n\\]\nso the average distance as the drone flies is equal to \\(2/3\\).\n\n\nCardinal scooter\nNow let’s figure out what the expected distance the scooter has to travel given a randomly chosen point in the City. Given a point \\((x,y)\\) in the disc, the distance (as the scooter drives) from the center to that point is given by\n\\[\n\\Vert(x,y)\\Vert_{\\text{scooter}} = \\vert x\\vert + \\vert y\\vert.\n\\]\nParameterizing the disc in polar coordinates to that \\(x=r\\cos\\theta\\) and \\(y=r\\sin\\theta\\), and this expression becomes \\(r(\\vert \\sin\\theta\\vert + \\vert \\cos\\theta\\vert)\\). To compute the expected distance in the taxicab metric, we can simplify the integral by integrating only over the quadrant where \\(\\cos\\theta\\) and \\(\\sin\\theta\\) are both positive and multiply the result by \\(4\\). We have\n\\[\n\\begin{align*}\nE_{\\text{scooter}}\n&= \\frac{1}{\\pi}\\int_{\\text{City}}r\\big(\\vert \\sin\\theta\\vert  + \\vert \\cos\\theta\\vert \\big)\\, \\operatorname{d}\\mspace{-1mu}A\\\\\n&= \\frac{4}{\\pi}\\int_0^{\\pi/2}\\int_0^1r^2(\\sin\\theta + \\cos\\theta)\\, \\operatorname{d} \\mspace{-1mu}r\\,\\operatorname{d} \\mspace{-1mu}\\theta\\\\\n&= \\frac{4}{\\pi}\\Big(\\int_0^{\\pi/2}(\\sin\\theta + \\cos\\theta)\\,\\operatorname{d} \\mspace{-1mu}\\theta\\Big)\\frac{1}{3}\\\\\n& = \\frac{8}{3\\pi}.\n\\end{align*}\n\\]\nNote that\n\\[\n\\frac{E_\\text{drone}}{E_{\\text{scooter}}} = \\frac{4}{\\pi} \\approx 1.27,\n\\]\nso the scooter needs to travel on average about 27% further to make the same delivery!\nIn the long run, the ratio of the number of deliveries that a drone can make in the same time as the scooter is equal to the same ratio, \\(4/\\pi\\). That is, the drone makes on average roughly 27% more deliveries.\n\n\nExtra credit: diagonal scooter\nAllowing the scooter to also travel along the diagonals gives rise to a new metric that we must now consider. Given a point \\((x,y)\\) in the City, the distance from this point to the center is the shortest path that the scooter can take to get there by traveling only along diagonals and orthogonal cross streets. How might we compute this metric? Let’s denote this metric as\n\\[\n\\Vert(x,y)\\Vert_{\\text{scooter*}}\n\\]\nwhere we use \\(\\text{scooter*}\\) to indicate the augmented scooter.\nTo examine the most efficient routes for the scooters, first note that, if the scooter can’t get to its destination by traveling in a single cardinal direction (i.e., needing only to go straight N, S, E, or W), traveling along a diagonal is much more efficient than traveling along two different cardinal directions.\nFor example, if a route involved some amount of travel on a street headed due north followed by a stretch of the same distance but headed due west, we could instead have arrived there in a more efficient manner by traveling northwest along the NW diagonal. This would get us to the same place but require a total travel distance equal to a fraction of \\(1/\\sqrt{2}\\) of the distance taken by only going north then west.\nThus, the most efficient routes for the scooter will always be to first take a diagonal as far as possible, until you are at a point where you can then travel a straight line in a single cardinal direction (N, S, E, or W) until you reach your destination.\nFor points in the first eighth slice of the City, we have the following diagram to help us find the shortest path.\n\n\n\nDiagonally augmented scooter distance\n\n\nThat is, the shortest path to the point \\((x,y)\\) is to travel NW along the diagonal until you are as far north as the destination, then travel due west until you arrive.\nIn this slice of the disc (i.e., all the points \\((x,y)\\) such that \\(0\\leq y\\leq x\\) and \\(x^2+y^2\\leq 1\\)), the augmented scooter distance evaluates to\n\\[\n\\begin{align*}\n\\Vert(x,y)\\Vert_\\text{scooter*} &= \\sqrt{2}y + (x-y)\\\\\n& = x + \\big(\\sqrt{2}-1\\big)y\n\\end{align*}\n\\]\nIn polar coordinates, this expression becomes\n\\[\nr\\big(\\cos\\theta + \\big(\\sqrt{2}-1\\big)\\sin\\theta\\big).\n\\]\nBy symmetry, the expected distance will be the same for all eight slices, so we can integrate over just this slice and divide by its area (\\(\\pi/8\\)) to get the expected distance over the whole City. Thus, we have\n\\[\n\\begin{align*}\nE_{\\text{scooter*}} & = \\frac{8}{\\pi}\\int_0^{\\pi/4}\\int_0^1 r\\Big(\\cos\\theta + \\big(\\sqrt{2}-1\\big)\\sin\\theta\\Big)r\\,\\operatorname{d} \\mspace{-1mu}r\\,\\operatorname{d} \\mspace{-1mu}\\theta\n\\\\\n& = \\frac{8}{\\pi}\\int_0^1 r^2\\, \\operatorname{d} \\mspace{-1mu}r \\int_0^{\\pi/4}\\big(\\cos\\theta + \\big(\\sqrt{2}-1\\big)\\sin\\theta\\big)\\,\\operatorname{d} \\mspace{-1mu}\\theta\\\\\n& = \\frac{8}{3\\pi}\\Bigg(\\frac{1}{\\sqrt{2}} + \\big(\\sqrt{2}-1\\big)\\left(1-\\frac{1}{\\sqrt{2}}\\right)\\Bigg)\\\\\n&=\\frac{8}{3\\pi}\\left(\\frac{1}{\\sqrt{2}}+\\left(\\frac{3}{\\sqrt{2}}-2\\right)\\right)\\\\\n&= \\frac{8}{3\\pi}2\\left(\\sqrt{2}-1\\right).\n\\end{align*}\n\\]\nHence, the average distance that the diagonal scooter travels is on average \\(2(\\sqrt{2}-1)\\approx0.828\\) times the distance that the regular scooter travels.\nIn relation to the drone, the ratio of the expected number of deliveries that the drone can make vs the scooter is equal to\n\\[\n\\frac{E_{\\text{scooter*}}}{E_{\\text{drone}}} = \\frac{8\\big(\\sqrt{2}-1\\big)}{\\pi}\\approx1.055,\n\\]\nso the drone only makes about 5.5% more deliveries than the diagonal scooter."
  },
  {
    "objectID": "blog/posts/2022-12-16-riddler-gift-exchange.html",
    "href": "blog/posts/2022-12-16-riddler-gift-exchange.html",
    "title": "Riddler: The Riddler Gift Exchange?",
    "section": "",
    "text": "My solution to this week’s riddler. (See more of my Riddler solutions here.)"
  },
  {
    "objectID": "blog/posts/2022-12-16-riddler-gift-exchange.html#the-problem",
    "href": "blog/posts/2022-12-16-riddler-gift-exchange.html#the-problem",
    "title": "Riddler: The Riddler Gift Exchange?",
    "section": "The Problem",
    "text": "The Problem\nFrom Gary Yane comes a puzzle that’s just in time for Christmas:\n\nEvery Christmas, Gary’s family has a gift exchange. And every year, there is a big fight over how much folks should spend on the gifts. This year, they decided to pair up. So if Virginia gives Justin a gift, then Justin gives Virginia a gift. This way, while there will still be arguments, only two people will be involved in each argument.\nThere are 20 people in the gift exchange. In the first round, everyone writes down the name of a random person (other than themselves) and the names go in a hat. Then if two people randomly pick each other’s names out of that hat, they will exchange gifts, and they no longer participate in the drawing. The remaining family members go on to round two. Again, they write down the name of anyone left, and again, any two people who pick each other exchange gifts.  \nThis continues until everyone is paired up. And yes, if exactly two people remain, they still go through the process of selecting each other, even though they know who their partner will be.\nOn average, what is the expected number of rounds until everyone is paired up?\n\nI misread the statement when I first read this, which resulted in me solving the wrong problem…. :(. It turns out that the actual problem is difficult to solve analytically, and without resorting to simulation I wasn’t able to come up with a solution.\n(Edit: After posting this, I found that no other solvers were able to find a solution that didn’t rely on simulation, so I don’t feel bad. Also, other solvers played around with my same misinterpretation of the problem!)\nHowever! My misinterpretation of the problem provided me with a similar problem that, although still relatively difficult, I was able to find an analytic solution to!\nIn the original problem statement, each participant writes down any name other than their own name. When I first read this, I thought that each participant writes exactly their own name. This minor variation makes the problem still interesting, but much easier to solve.\nSo, for the rest of the post I will focus on the solution to the variant problem where each participant writes their own name. Putting the names into the hat and redistributing them to the participants is essentially a standard permutation of the names. The number of outcomes different outcomes at the end of a given round is just the number of permutations of the participants. What makes this easy is that we guarantee that each name is in the hat exactly once, something that doesn’t happen in the original problem statement."
  },
  {
    "objectID": "blog/posts/2022-12-16-riddler-gift-exchange.html#solution-to-the-variant-problem",
    "href": "blog/posts/2022-12-16-riddler-gift-exchange.html#solution-to-the-variant-problem",
    "title": "Riddler: The Riddler Gift Exchange?",
    "section": "Solution (to the variant problem)",
    "text": "Solution (to the variant problem)\nIn the variant problem that I considered, each participant writes their own name on the slip of paper and puts it into the hat. The names are then randomly permuted and given back to the participants.\nSuppose there are \\(n\\) initial participants. (Note that \\(n\\) must be even or the game doesn’t work.) Miraculously, it turns out that the expected number of rounds that must be played until completion is simply \\(n\\).\nThat is, if we let \\(E_n\\) denote the expected number of rounds that must be played in a game that starts with \\(n\\) players until every one is paired off, it holds that\n\\[\nE_n = n\n\\]\nwhen \\(n\\) is even (and \\(E_n=\\infty\\) otherwise).\nDespite the solution having a simple expression, I was unable to come up with a simple argument. I have a long convoluted method to determine this answer, that involves counting certain types of permutations. The proof is convoluted, but the simple expression for the answer makes me believe that perhaps there is a simpler way… oh well.\n\nPermutations and cycles\nSuppose there are \\(n\\) participants at the start of a given round. We may identify the names with the numbers \\(1\\) to \\(n\\). The set of permutations of \\(\\lbrace 1,2,\\dots, n\\rbrace\\) is denoted \\(S_n\\) (i.e., the symmetric group of \\(n\\) elements). Now, when does a permutation of the participants have two people perfectly pair up? This requires two people to take each other’s names. We can express this mathematically by saying that the permutation has a cycle of size 2.\nLet’s recall now the cycle representation of a permutation. Consider the permutation \\(\\pi\\in S_6\\) defined by the following diagram:\n\n\n\nA permutation\n\n\nWe can picture this in our game as person 1 drawing person 5’s name, person 5 drew person 3’s name, and person 3 drew person 1’s name. Person 4 drew their own name while participants 2 and 6 drew each others names. In this way, we can see that the permutation splits out nicely into three disjoint cycles. In cycle notation, we can express this permutation as\n\\[\n(153)(26)(4),\n\\]\nwhich has cycles of size 1, 2 and 3. The length of the cycle is the number of elements it cycles through. A cycle of length \\(k\\) is called a \\(k\\)-cycle. The number of pairs that form in a given round is equal to the number of disjoint \\(2\\)-cycles in the permutation! In this example, players 2 and 6 pair off in the gift exchange, and the four remaining players (1, 3, 4, and 5) that are not part of a \\(2\\)-cycle continue on to the next round and place their names back in the had.\n\n\nPairing up\nSuppose at the start of a round there are \\(n\\) people remaining in the group of yet-to-be-paired-off participants. A random permutation of the \\(n\\) names is chosen as the participants draw names out of the hat. If the permutation has \\(k\\) disjoint \\(2\\)-cycles, then \\(2k\\) of those participants pair off in to \\(k\\) pairs and there are \\(n-2k\\) participants remaining in the pool in the next round.\nWhen there only two people remaining, there are two possibilities that each occur with 50% probability: either they choose each other’s names (pairing up) or they choose their own names and continue to another round. Since each round has a 50% chance of ending the game and a 50% chance of continuing to another round, the expected number of rounds to be had once their are two people remaining is\n\\[\n1 + \\frac{1}{2} + \\frac{1}{2^2} + \\cdots = 2.\n\\]\nNow, the question we want to answer is: If there are \\(n\\) participants initially, what is the expected number of rounds until all participants have been paired off this way? We can set this problem up mathematically as follows.\nFor non-negative integers \\(n\\) and \\(k\\): - Let \\(p_{n,k}\\) be the probability that a randomly selected permutation of \\(n\\) elements contains exactly \\(k\\) disjoint \\(2\\)-cycles, and - Let \\(E_n\\) denote the expected number of rounds that the game will last when it begins with \\(n\\) participants. When \\(n=0\\), there is no game to be played as there are no remaining participants to pair up and thus \\(E_0 = 0\\). However, if \\(n\\) is odd then it will be impossible to pair off everybody in the group, and thus \\(E_n\\) is infinite. We have already determined that \\(E_2=2\\).\nOtherwise, if \\(n\\) is even and positive, then \\(n=2m\\) for some positive integer \\(m\\). In a round that starts with \\(2m\\) players there will be some number \\(k\\in\\lbrace 0,1,\\dots, m\\rbrace\\) of pairs that form, and the next round starts with \\(E_{2m-2k}\\) players. It follows that\n\\[\nE_{2m} = 1 + \\sum_{k=0}^{m} p_{2m,k} E_{2(m-k)}.\n\\]\nSlightly rearranging and solving for \\(E_n\\) (and using the fact that \\(E_0=0\\)), we find that\n\\[\nE_{2m}= \\frac{1}{1-p_{2m,0}}\\left(1 + \\sum_{k=1}^{m-1}p_{2m,k}E_{2(m-k)}\\right).\n\\]\nIt remains now to find an expression for \\(p_{n,k}\\). If we let \\(a_{n,k}\\) denote the number of permutations of \\(n\\) elements that contain exactly \\(k\\) distinct \\(2\\)-cycles, then we may write\n\\[\np_{n,k} = \\frac{a_{n,k}}{n!}.\n\\]\nThe latter half of this blog post will be devoted to proving the following claim.\n\nClaim. Let \\(n\\) and \\(k\\) be nonnegative integers. The number of permutations of \\(n\\) elements that contain exactly \\(k\\) distinct \\(2\\)-cycles is given by \\[a_{n,k} = \\frac{n!}{2^kk!}\\sum_{j=0}^{\\lfloor n/2-k\\rfloor}\\frac{(-1)^{j} }{2^j j!}.\\]\n\nThe proof of this claim will follow later, but for now we can carry onward. The desired probability may therefore be expressed as\n\\[\np_{n,k} = \\frac{1}{2^k k!}\\sum_{j=0}^{\\lfloor n/2-k\\rfloor}\\frac{(-1)^{j} }{2^j j!}.\n\\]\nNow, when \\(n=2m\\), this simplifies to\n\\[\np_{2m,k} = \\frac{1}{2^k k!}\\sum_{j=0}^{m-k}\\frac{(-1)^{j} }{2^j j!}.\n\\]\nFor a sanity check, we can verify for a fixed \\(m\\) that the sum of all of these probabilities equals one. Indeed, if there are \\(2m\\) people, the numbers of different pairs that can form are \\(0,1,\\dots m\\), and\n\\[\n\\begin{align*}\n\\sum_{k=0}^m p_{2m,k}\n&= \\sum_{k=0}^m\\sum_{j=0}^{m-k}\\frac{(-1)^j}{2^{k+j}k!j!}\\\\\n&= \\sum_{k=0}^m\\sum_{j=0}^{m-k}\\frac{(-1)^j}{2^{k+j}(k+j)!}\\binom{k+j}{j}\\\\\n& = \\sum_{a=0}^m\\sum_{j=0}^a \\frac{(-1)^j}{2^aa!}\\binom{a}{j}\\\\\n& = \\sum_{a=0}^m\\frac{1}{2^aa!}\\sum_{j=0}^a (1)^{a-j}(-1)^j\\binom{a}{j}\\\\\n& = 1 + \\sum_{a=1}^m\\frac{1}{2^aa!}(1-1)^a\\\\\n& = 1.\n\\end{align*}\n\\]\nWe proceed now with the statement of the main result.\n\nProposition. Let \\(E_n\\) denote the expected number of rounds in a game that starts with \\(n\\) players. It holds that\n\n\\[\nE_{2m} = 2m\n\\]\n\nfor all \\(m\\in\\mathbb{N}\\).\n\nProof. We proceed by induction. As discussed above, the trivial game requires no rounds so \\(E_0=0\\). Let \\(m\\in\\mathbb{N}\\) and suppose that \\(E_{2k} = 2k\\) holds for all integers \\(k\\in\\lbrace 0,1,\\dots,m\\rbrace\\). Note that\n\\[\\tag{$\\ast$}\nE_{2m} = \\sum_{k=1}^m p_{2m,m-k}E_{2k}= 2m\n\\]\nby assumption. Also note that for each \\(k\\in\\mathbb{N}\\) we have that\n\\[\\tag{$\\ast\\ast$}\n\\begin{align*}\np_{2(m+1),k}\n&= \\frac{1}{2^kk!}\\Bigg(\\sum_{j=1}^{m-k}\\frac{(-1)^j}{2^j j!} + \\frac{(-1)^{m+1-k}}{2^{m+1-k}(m+1-k)!}\\Bigg)\\\\\n& = p_{2m,k} - \\frac{(-1)^{m-k}}{2^{m+1}(m+1)!}\\binom{m+1}{k}\n\\end{align*}\n\\]\nand in particular\n\\[\\tag{$\\ast\\ast\\ast$}\np_{2(m+1),0} = p_{2m,0} - \\frac{(-1)^{m}}{2^{m+1}(m+1)!}.\n\\]\nNote that\n\\[\n\\begin{align*}\n\\sum_{k=1}^{m}p_{2m,m+1-k}E_{2k}\n& = \\sum_{k=0}^{m-1}p_{2m,m-k}E_{2k+2}\\\\\n& = \\sum_{k=0}^{m-1}p_{2m,m-k}(2k+2)\\\\\n& = \\sum_{k=0}^{m-1}p_{2m,m-k}(2k) +2\\sum_{k=0}^{m-1}p_{2m,m-k}\\\\\n& = \\sum_{k=0}^{m-1}p_{2m,m-k}E_{2k} + 2\\big(1-p_{2m,0}\\big)\\\\\n& = \\big(E_{2m} - p_{2m,0}E_{2m}\\big) + 2\\big(1-p_{2m,0}\\big)\\\\\n& = (E_{2m}+2)\\big(1-p_{2m,0}\\big)\\\\\n& = (2m+2)\\big(1-p_{2m,0}\\big),\n\\end{align*}\n\\]\nwhere we make use of (\\(\\ast\\)).\nAlso,\n\\[\n\\begin{align*}\n\\sum_{k=1}^{m}\\frac{(1)^{k+1}}{2^{m+1}(m+1-k)!k!}E_{2k}\n& =  \\frac{1}{2^{m+1}} \\sum_{k=1}^{m}\\frac{(-1)^{k-1}}{(m+1-k)!k!}E_{2k}\\\\\n&= \\frac{1}{2^{m+1}} \\sum_{k=1}^{m}\\frac{(-1)^{k-1}}{(m+1-k)!k!}(2k)\\\\\n&=\\frac{1}{2^{m}} \\sum_{k=1}^{m}\\frac{(-1)^{k-1}}{(m+1-k)!(k-1)!}\\\\\n&=\\frac{1}{2^{m}} \\sum_{k=0}^{m-1}\\frac{(-1)^{k}}{(m-k)!k!}\\\\\n&=\\frac{1}{2^{m}m!} \\sum_{k=0}^{m-1}(-1)^{k}\\binom{m}{k}\\\\\n&=\\frac{1}{2^{m}m!} \\Bigg(\\sum_{k=0}^{m}(-1)^{k}\\binom{m}{k}-(-1)^m\\Bigg)\\\\\n&=\\frac{(-1)^m}{2^{m}m!}\n\\end{align*}\n\\]\nPutting this together using (\\(\\ast\\ast\\)) and (\\(\\ast\\ast\\ast\\)), we have\n\\[\n\\begin{align*}\n\\sum_{k=1}^m p_{2(m+1), m+1-k}E_{2k}\n& =  \\Bigg(\\sum_{k=1}^{m}p_{2m,m+1-k}E_{2k} \\Bigg) + \\Bigg(\\sum_{k=1}^{m}\\frac{(-1)^{k+1}}{2^{m+1}(m+1-k)!k!}E_{2k}\\Bigg)\\\\\n& = (2m+2)\\big(1-p_{2m,0}\\big) + \\frac{(-1)^m}{2^{m}m!}\\\\\n& = 2(m+1)\\big(1-p_{2m,0}\\big) -2(m+1) \\frac{(-1)^{m+1}}{2^{m+1}(m+1)!}\\\\\n& = 2(m+1)\\bigg(1-p_{2m,0} - \\frac{(-1)^{m+1}}{2^{m+1}(m+1)!}\\bigg)\\\\\n& = 2(m+1)(1-p_{2(m+1),0}).\n\\end{align*}\n\\]\nFinally,\n\\[\n\\begin{align*}\nE_{2(m+1)}\n&= \\frac{1}{1-p_{2(m+1),0}}\\sum_{k=1}^m p_{2(m+1), m+1-k}E_{2k}\\\\\n&= 2(m+1),\n\\end{align*}\n\\]\nas desired. \\(\\square\\)"
  },
  {
    "objectID": "blog/posts/2022-12-16-riddler-gift-exchange.html#proof-of-the-claim-counting-permutations-with-k-disjoint-2-cycles",
    "href": "blog/posts/2022-12-16-riddler-gift-exchange.html#proof-of-the-claim-counting-permutations-with-k-disjoint-2-cycles",
    "title": "Riddler: The Riddler Gift Exchange?",
    "section": "Proof of the claim: Counting permutations with \\(k\\) disjoint 2-cycles",
    "text": "Proof of the claim: Counting permutations with \\(k\\) disjoint 2-cycles\nThe rest of this post is devoted to proving the claim above. Let \\(n\\) and \\(k\\) be nonnegative integers. We want to find an expression for \\(a_{n,k}\\), which denotes the number of permutations in \\(S_n\\) containing exactly \\(k\\) disjoint 2-cycles. We may count these permutations by first choosing the \\(2k\\) elements that will compose the \\(k\\) pairs that are formed, then count the number of ways those \\(2k\\) elements can be paired off, and finally count the number of ways that the remaining \\(n-2k\\) elements can be permuted with no 2-cycles. Hence, one has that\n\\[\na_{n,k}=\\binom{n}{2k}a_{2k,k}a_{n-2k,0}.\n\\]\nNote that\n\\[\na_{2k,k}=\\frac{(2k)!}{2^kk!}.\n\\]\nTo see this, note that we can count the number of ways to partition \\(2k\\) elements into \\(k\\) disjoint ordered pairs in two different ways. One way is to partition the \\(2k\\) elements into \\(k\\) unordered pairs, then decide on an ordering for each pair. Another way is to choose \\(k\\) of the \\(2k\\) elements to be the first elements of each pair, then arrange the remaining \\(k\\) elements with the chosen \\(k\\) elements. It follows that \\[a_{2k,k}2^k=\\binom{2k}{k}k!\\]and the result follows. It remains to determine an expression for \\(a_{m,0}\\) for an integer \\(m\\).\n\nPermutations with no 2-cycles\nNote that \\(a_{m,0}\\) is the number of permutations of \\(m\\) elements containing no 2-cycles. To find an expression for this number, for each distinct subset $i,j,2,,m$ of exactly two elements, define \\(A_{\\lbrace i,j\\rbrace}\\) as the set of all permutations of $,2,,m$ for which \\((ij)\\) is a 2-cycle. That is,\n\\[\nA_{\\lbrace i,j\\rbrace } = \\lbrace \\pi\\in S_m\\,:\\, \\pi(i)=j,\\, \\pi(j)=i\\rbrace .\n\\]\nThe collection of all permutations in \\(S_m\\) that have no 2-cycles can be expressed as\n\\[\nS_n\\setminus \\Bigg(\\bigcup_{\\substack{i,j\\in\\lbrace 1,2,\\dots,m\\rbrace \\\\i\\neq j}}A_{\\lbrace i,j\\rbrace }\\Bigg).\\tag{1}\n\\]\nThe cardinality of this set is equal to \\(a_{m,0}\\). We will prove that\n\\[\na_{m,0} = m!\\sum_{k=0}^{\\lfloor m/2\\rfloor}\\frac{(-1)^{k} }{2^k k!}.\n\\]\n\nInclusion–Exclusion Principle\nIf one wants to count the number of elements in the union \\(A\\cup B\\) of two finite sets \\(A\\) and \\(B\\), one way to do this is to use the formula \\[\\vert A\\cup B\\vert  = \\vert A\\vert  + \\vert B\\vert  - \\vert A\\cap B\\vert .\\]This can be observed that $A+B$ is too large, because the elements in the intersection have been double counted. This technique can be generalizes to any finite number of finite sets.\nLet $A_a,:, a$ be a finite family of finite sets indexed by some finite index set \\(\\Omega\\). First some notation. For a fixed integer \\(k\\), the collection of all subsets of \\(\\Omega\\) having exactly \\(k\\) elements is expressed as\n\\[\n\\binom{\\Omega}{k} = \\lbrace B\\subset \\Omega\\,:\\, \\vert B\\vert =k\\rbrace .\n\\]\nTo count the number of elements in the union of every set in $A_a,:,a$, we can count the number of elements the intersection of every possible subfamily and apply a useful formula. Namely,\n\\[\n\\bigg\\vert \\bigcup_{a\\in\\Omega}A_a\\bigg\\vert  = \\sum_{k=1}^{\\vert \\Omega\\vert }(-1)^{k+1} \\sum_{B\\in\\binom{\\Omega}{k}}\\bigg\\vert \\bigcap_{b\\in B}A_b\\bigg\\vert .\n\\]\nIn words, to count the number of elements in a finite union of finite sets, first sum the cardinalities of the individual sets, then subtract cardinalities of all possible intersections of two different sets, then add back the cardinalities of each possible intersection of three different sets, and so on.\n\n\nApplying the inclusion–exclusion principle\nLet us now use the inclusion–exclusion principle to find an expression for the cardinality of the set in (1). For brevity we use the notation\n\\[\n\\Omega_m=\\lbrace 1,2,\\dots,m\\rbrace .\n\\]\nFor an integer \\(k\\), we define\n\\[\nB_{m,k} = \\displaystyle\\binom{\\textstyle{\\binom{\\Omega_m}{2}}}{\\textstyle k}\n\\]\nas the collection of all sets of \\(k\\) distinct pairs of elements of \\(\\Omega_m\\). For example,\n\\[\nB_{3,2} = \\Big\\lbrace \\big\\lbrace \\lbrace 1,2\\rbrace ,\\lbrace 1,3\\rbrace \\big\\rbrace ,\\, \\big\\lbrace \\lbrace 1,2\\rbrace ,\\lbrace 2,3\\rbrace \\big\\rbrace ,\\, \\big\\lbrace \\lbrace 1,3\\rbrace ,\\lbrace 2,3\\rbrace \\big\\rbrace \\Big\\rbrace\n\\]\nNote that\n\\[\n\\begin{align*}\n\\Bigg\\vert \\bigcup_{\\substack{\\lbrace i,j\\rbrace \\in\\binom{\\Omega_m}{2}}} A_{\\lbrace i,j\\rbrace } \\Bigg\\vert = \\sum_{k=1}^{\\big\\vert \\binom{\\Omega_m}{2}\\big\\vert }(-1)^{k+1}\\sum_{B\\in B_{m,k}} \\bigg\\vert\\bigcap_{\\lbrace i,j\\rbrace \\in B}A_{\\lbrace i,j\\rbrace }\\bigg\\vert.\n\\end{align*}\n\\]\nNow, if a collection \\(B\\in B_{m,k}\\) is not pairwise disjoint then one has that\n\\[\n\\bigcap_{\\lbrace i,j\\rbrace \\in B}A_{\\lbrace i,j\\rbrace } = \\emptyset.\n\\]\nIndeed, an element of $_m=,2,,m$ cannot be in more than one 2-cycle of a given permutation of \\(\\Omega_m\\). The only non-empty intersections are those where the family \\(B\\) consists of pairwise disjoint subsets of size 2.\nA family \\(B\\in B_{m,k}\\) that is pairwise disjoint is of the form\n\\[\nB = \\big\\lbrace \\lbrace i_1,j_1\\rbrace ,\\dots,\\lbrace i_k,j_k\\rbrace \\big\\rbrace ,\n\\]\nwhere the elements \\(i_1,\\dots,i_k,j_1,\\dots,j_k\\) are all distinct.\nTo find the cardinality of \\(A_{\\lbrace i_1,j_1\\rbrace }\\cap\\cdots\\cap A_{\\lbrace i_k,j_k\\rbrace }\\), we count the number of permutations that contain the \\(k\\) 2-cycles \\((i_1,j_1), \\cdots, (i_kj_k)\\). To do so, we simply count the number of ways that the remaining \\(m-2k\\) elements can be permuted, and thus\n\\[\n\\bigg\\vert \\bigcap_{\\lbrace i,j\\rbrace \\in B}A_{\\lbrace i,j\\rbrace }\\bigg\\vert  = (m-2k)!.\n\\]\nThe number of families \\(B\\in B_{m,k}\\) that are pairwise disjoint is equal to\n\\[\n\\binom{m}{2k}a_{2k,k} = \\binom{m}{2k}\\frac{(2k)!}{2^k k!},\n\\]\nas we may simply count the number of ways to select \\(2k\\) elements from $,2,,m$ and subsequently decide how to pair up those \\(2k\\) elements into \\(k\\) pairs.\nIt follows that\n\\[\n\\begin{align*}\n\\bigcup_{\\substack{\\lbrace i,j\\rbrace \\in\\binom{\\Omega_m}{2}}} A_{\\lbrace i,j\\rbrace }\n&= \\sum_{k=1}^{\\lfloor m/2\\rfloor}(-1)^{k+1}\\binom{m}{2k}\\frac{(2k)!}{2^k k!}(m-2k)!\\\\\n& = m!\\sum_{k=1}^{\\lfloor m/2\\rfloor}\\frac{(-1)^{k+1} }{2^k k!}\n\\end{align*}\n\\]\nFinally, the number of permutations of $,2,,m$ containing no 2-cycles is equal to\n\\[\n\\begin{align*}\na_{m,0}\n&= m! - m!\\sum_{k=1}^{\\lfloor m/2\\rfloor}\\frac{(-1)^{k+1} }{2^k k!} \\\\\n&= m!\\sum_{k=0}^{\\lfloor m/2\\rfloor}\\frac{(-1)^{k} }{2^k k!},\n\\end{align*}\n\\]\nas desired.\n\n\n\nBack to permutations with \\(k\\) disjoint 2-cycles\nWe finally return to counting the permutations of \\(\\lbrace 1,2,\\dots,n\\rbrace\\) that contain exactly \\(k\\) disjoint 2-cycles. This is\n\\[\n\\begin{align*}\na_{n,k}\n& = \\binom{n}{2k}a_{2k,k}a_{n-2k,0}\\\\\n& = \\binom{n}{2k}\\frac{(2k)!}{2^kk!} (n-2k)!\\sum_{j=0}^{\\lfloor n/2-k\\rfloor}\\frac{(-1)^{j} }{2^j j!}\\\\\n& = \\frac{n!}{2^kk!}\\sum_{j=0}^{\\lfloor n/2-k\\rfloor}\\frac{(-1)^{j} }{2^j j!}\n\\end{align*}\n\\]\nwhich proves the claim."
  },
  {
    "objectID": "blog/posts/2022-10-14-birthday-party.html",
    "href": "blog/posts/2022-10-14-birthday-party.html",
    "title": "Riddler: How big is your birthday surprise party?",
    "section": "",
    "text": "My solution to this week’s riddler. (See more of my Riddler solutions here.)"
  },
  {
    "objectID": "blog/posts/2022-10-14-birthday-party.html#the-problem",
    "href": "blog/posts/2022-10-14-birthday-party.html#the-problem",
    "title": "Riddler: How big is your birthday surprise party?",
    "section": "The Problem",
    "text": "The Problem\n\nToday I happen to be celebrating the birthday of a family member, which got me wondering about how likely it is for two people in a room to have the same birthday.\nSuppose people walk into a room, one at a time. Their birthdays happen to be randomly distributed throughout the 365 days of the year (and no one was born on a leap day). The moment two people in the room have the same birthday, no more people enter the room and everyone inside celebrates by eating cake, regardless of whether that common birthday happens to be today.\nOn average, what is the expected number of people in the room when they eat cake?\nExtra credit: Suppose everyone eats cake the moment three people in the room have the same birthday. On average, what is this expected number of people?"
  },
  {
    "objectID": "blog/posts/2022-10-14-birthday-party.html#the-solution",
    "href": "blog/posts/2022-10-14-birthday-party.html#the-solution",
    "title": "Riddler: How big is your birthday surprise party?",
    "section": "The Solution",
    "text": "The Solution\nFor each pair of non-negative integers \\(n\\) and \\(k\\), let \\(p_{n,k}\\) denote the probability that no \\(k\\) people share a birthday when there are \\(n\\) guests present. Also define \\(E_k\\) as the expected number of guests that must arrive for there to be \\(k\\) people that share a birthday. The first observation that we will make is that\n\\[\nE_k  = \\sum_{n=0}^\\infty p_{n,k}.\n\\]\nIndeed, if we define random variables \\(X_{n,k}\\) as\n\\[\nX_{n,k} = \\left\\{\\begin{array}{ll}\n0, & \\text{if at least }k \\text{ guests share a birthday after }n\\text{ guests have arrived}\\\\\n1, &\\text{otherwise},\n\\end{array}\\right.\n\\]\nthen the total number of guests that have arrived at the first time there is a \\(k\\)-fold shared birthday is the random variable\n\\[\nX_k = X_{0,k} + X_{1,k} + \\cdots +  X_{365(k-1),k}.\n\\]\nThe expected value of this random variable is\n\\[\n\\begin{align*}\nE_k = \\operatorname{E}(X_k)\n&= \\sum_{n=0}^{365(k-1)} \\operatorname{E}(X_{n,k})\\\\\n&=\\sum_{n=0}^\\infty p_{n,k}\n\\end{align*}\n\\]\nwhere we note that \\(p_{n,k}=0\\) whenever \\(n&gt;365(k-1)\\) (because, by the pigeonhole principle, there must otherwise be at least one day on which at least \\(k\\) guests share a birthday). Also note that \\(p_{0,k}=1\\) for every \\(k\\geq1\\) (as there can be no shared birthdays if no guests are present).\nNow, the number of distinct ways in which \\(n\\) guests can arrive such that there is no day on which at least \\(k\\) of them share a birthday is equal to the number of ordered sequences \\[(a_1,a_2,\\dots,a_n)\\] of numbers \\[a_1,\\dots,a_n\\in\\{1,\\dots,365\\}\\] such that no number appears more than \\(k-1\\) times. The number of such sequences is equal to\n\\[\n\\sum_{\\substack{k_1,\\dots,k_{365}\\in\\{0,1,\\dots,k-1\\}\\\\k_1+k_2+\\cdots+k_{365}= n}}\n\\binom{n}{k_1,k_2,\\dots,k_{365}}\n\\]\nwhere\n\\[\n\\binom{n}{k_1,k_2,\\dots,k_{365}} = \\frac{n!}{k_1!k_2!\\cdots k_{365}!}\n\\]\nis the multinomial coefficient. Because there are \\(365^n\\) ways in which \\(n\\) guests can arrive in order, the probability that no \\(k\\) guests share a birthday after \\(n\\) guests have arrived is\n\\[\n\\begin{align*}\np_{n,k} &= \\frac{n!}{365^n}\\sum_{\\substack{k_1,\\dots,k_{365}\\in\\{0,1,\\dots,k-1\\}\\\\k_1+k_2+\\cdots+k_{365}= n}} \\frac{1}{k_1!k_2!\\cdots k_{365}!}\n\\\\\n&= \\sum_{\\substack{k_1,\\dots,k_{365}\\in\\{0,1,\\dots,k-1\\}\\\\k_1+k_2+\\cdots+k_{365}= n}} \\frac{1}{365^{k_1+k_2+\\cdots +k_{365}}}\\frac{(k_1+k_2\\cdots k_{365})!}{k_1!k_2!\\cdots k_{365}!}.\n\\end{align*}\n\\]\nWe now may express the desired expected values as\n\\[\n\\begin{align*}\nE_k\n&= \\sum_{n=0}^\\infty \\sum_{\\substack{k_1,\\dots,k_{365}\\in\\{0,1,\\dots,k-1\\}\\\\k_1+k_2+\\cdots+k_{365}= n}} \\frac{1}{365^{k_1+k_2+\\cdots +k_{365}}}\\frac{(k_1+k_2\\cdots k_{365})!}{k_1!k_2!\\cdots k_{365}!}\\\\\n& = \\sum_{k_1,\\dots,k_{365}\\in\\{0,1,\\dots,k-1\\}}\n\\frac{1}{365^{k_1+k_2+\\cdots +k_{365}}}\\frac{(k_1+k_2\\cdots k_{365})!}{k_1!k_2!\\cdots k_{365}!}.\n\\end{align*}\n\\]\nMaking use of the fact that\n\\[\nn! = \\int_{0}^\\infty t^n e^{-t}\\, \\mathrm{d}t\n\\]\nholds for every non-negative integer \\(n\\), we may compute the expected values as\n\\[\n\\begin{align*}\nE_k &\n= \\sum_{k_1,\\dots,k_{365}\\in\\{0,1,\\dots,k-1\\}} \\frac{1}{365^{k_1+k_2+\\cdots k_{365}}}\\frac{1}{k_1!k_2!\\cdots k_{365}!} \\int_{0}^\\infty t^{k_1+k_2+\\cdots+k_{365}} e^{-t}\\, \\mathrm{d}t\\\\\n& = \\int_{0}^\\infty \\sum_{k_1,\\dots,k_{365}\\in\\{0,1,\\dots,k-1\\}}\n\\left(\n   \\frac{\\left(\\frac{t}{365}\\right)^{k_1}}{k_1!} \\cdots \\frac{\\left(\\frac{t}{365}\\right)^{k_{365}}}{k_{365}!}\n   \\right)\n   e^{-t}\\, \\mathrm{d}t\\\\\n& = \\int_{0}^\\infty\n\\left(\n   \\sum_{n=0}^{k-1} \\frac{\\left(\\frac{t}{365}\\right)^{n}} {n!}\n   \\right)^{365}\n   e^{-t}\\, \\mathrm{d}t\\\\\n& = 365\\int_{0}^\\infty \\left(e^{-t}\\sum_{n=0}^{k-1}\\frac{t^n}{n!}\\right)^{365}\\, \\mathrm{d}t,\n\\end{align*}\n\\]\nwhere the last line follows after making a change of variables in the integration.\nUsing this formula, we can now compute the expected numbers of guests that have arrived at the first instance when \\(k\\) people share a birthday for different values of \\(k\\), the first few values are shown in the table below.\nfrom scipy.integrate import quad\nfrom scipy.special import factorial\n\ndef E(k, m=365):\n\n    def integrand(t):\n        out = (sum(np.exp(n*math.log(t) - t) / factorial(n) for n in range(k))) ** m\n        return out\n\n    return quad(integrand, 0, np.inf)\n\n\n\n\\(k\\)\n\\(E_k\\)\n\n\n\n\n1\n1.0\n\n\n2\n24.6166\n\n\n3\n88.7389\n\n\n4\n187.0518\n\n\n5\n311.4494\n\n\n6\n456.0163\n\n\n7\n616.6169\n\n\n8\n790.2997\n\n\n9\n974.8939\n\n\n10\n1168.7567\n\n\n11\n1370.6135\n\n\n12\n1579.4531\n\n\n13\n1794.459\n\n\n14\n2014.9607\n\n\n15\n2240.3999\n\n\n16\n2470.3065\n\n\n17\n2704.2798\n\n\n18\n2941.9755\n\n\n19\n3183.095\n\n\n20\n3427.3773\n\n\n21\n3674.5931\n\n\n22\n3924.5391\n\n\n23\n4177.0347\n\n\n24\n4431.918\n\n\n25\n4689.0437\n\n\n\nBelow are some plots of these values.\n\n\n\nExpected size of party the first time when there are k people who share a birthday.\n\n\n\n\n\nGrowth of expected party size as k increases appears to be linear, and approaches \\(365k\\) in the limit of large \\(k\\).\n\n\nIt seems that, in the limit of large \\(k\\), the ratio of the expected party size to the maximum party size of \\(\\sim365k\\) approaches 1."
  },
  {
    "objectID": "blog/posts/2022-09-09-riddler-overlapping-disks.html",
    "href": "blog/posts/2022-09-09-riddler-overlapping-disks.html",
    "title": "Riddler: Overlapping Disks",
    "section": "",
    "text": "Here’s my solution to this week’s Riddler. (See more of my Riddler solutions here.)"
  },
  {
    "objectID": "blog/posts/2022-09-09-riddler-overlapping-disks.html#the-problem",
    "href": "blog/posts/2022-09-09-riddler-overlapping-disks.html#the-problem",
    "title": "Riddler: Overlapping Disks",
    "section": "The Problem",
    "text": "The Problem\n\nSuppose you have a unit square (i.e., with side length 1). If you also have four identical circles that can overlap, they would need to have a radius of \\(\\sqrt{2}/4\\) to completely cover the square, as shown below:\n\nNow suppose that, instead of four identical circles, you have five identical circles that can overlap. What is the minimum radius they would need to completely cover a unit square?\nExtra credit: Suppose you have six identical circles that can overlap. What is the minimum radius they would need to completely cover a unit square?"
  },
  {
    "objectID": "blog/posts/2022-09-09-riddler-overlapping-disks.html#the-solution",
    "href": "blog/posts/2022-09-09-riddler-overlapping-disks.html#the-solution",
    "title": "Riddler: Overlapping Disks",
    "section": "The Solution",
    "text": "The Solution\nInterestingly this problem appears to have been previously solved (more on that in a minute). But first, my solution: ### My solution I guessed that the best solution would have a bit of reflectional symmetry. With the help of some amazing geometric drawing software (Geogebra), I was able to come up with a solution with \\(r\\approx 0.326\\) with the diagram below:\n\n\n\nA Geogebra drawing of 5 disks of minimal radius covering the unit square.\n\n\nNote that \\(0.326&lt;.3535 \\approx\\frac{1}{2\\sqrt{2}}\\) so this solution is definitely an improvement over simply covering the square with 4 squares.\nI wanted to come up with a more exact value. By expressing the coordinates of the centres of the five circles in this geometric picture as\n\\[\n\\left(-\\frac{1}{4}, a\\right),\\, \\left(\\frac{1}{4}, a\\right), \\, \\left(-d, -b\\right), \\, \\left(d, -b\\right),\\,\\text{and}\\, \\left(0, -c\\right),\n\\]\nand doing a little bit of work, we can set up a system of equations that the values \\(a\\), \\(b\\), \\(c\\), \\(d\\), and \\(r\\) must satisfy (where \\(e=\\frac{1}{4}\\)):\n\\[\n\\begin{align}\nr^2&=\\left(\\frac{1}{2}-a\\right)^2+\\frac{1}{16.}\\\\\nr^2&=\\left(\\frac{1}{2}-b\\right)^2+\\left(\\frac{1}{2}-d\\right)^2\\\\\nr^2&=\\left(\\frac{1}{2}-c\\right)^2+\\left(2d-\\frac{1}{2}\\right)^2\\\\\nb&=\\frac{1}{2}-a\\\\\nr&=2a+c-\\frac{1}{2}\n\\end{align}\n\\]\nWith the help of Mathematica, I was able to determine that the only solution to this (with \\(a\\), \\(b\\), \\(c\\), \\(d\\), and \\(r\\) all positive) is given by\n\\[\n\\begin{align}\na&=-\\frac{23808 r^5}{1159}+\\frac{2208 r^4}{1159}+\\frac{1819 r^3}{1159}+\\frac{259 r^2}{244}-\\frac{13959 r}{18544}+\\frac{31371}{74176}\\\\\nb&=\\frac{1}{2}-a\\\\\nc&=2 b+r-\\frac{1}{2}\\\\\nd&=\\frac{10368 r^5}{1159}+\\frac{3824 r^4}{1159}-\\frac{9959 r^3}{2318}-\\frac{1603 r^2}{488}+\\frac{15747 r}{37088}+\\frac{95157}{148352}\n\\end{align}\n\\]\nwhere \\(r\\approx0.32616\\) is the smallest real root of the polynomial equation\n\\[\n425 - 672 x + 352 x^2 - 10240 x^3 + 256 x^4 + 8192 x^5 + 65536 x^6 = 0.\n\\]\n[Edit (18-09-2022): Note that a previous version of the post had an incorrect solution here.]\n\nPrevious work\nAfter a bit of Googling, I was able to stumble upon a few papers that had investigated this and similar problems. By far the best one was Covering a square with up to 30 equal circles. by Nurmela and Östergård (2000). In that work, the authors developed a clever optimization algorithm to determine the smallest radius of circle such that \\(n\\) circles of that size can be used to cover the unit square for \\(n\\) up to 30. Here are the figures for \\(n=5\\) and \\(n=6\\).\n\n\n\nMinimal radius coverings with 5 and 6 disks.\n\n\nThe authors determined the optimal radii for \\(5\\) and \\(6\\) circles to be \\(r_5=0.32616058400398728086\\) and \\(r_6=0.29872706223691915876\\) respectively."
  },
  {
    "objectID": "academic/teaching/math137_2020/index.html",
    "href": "academic/teaching/math137_2020/index.html",
    "title": "MATH 137: Calculus I Honours (Fall 2020)",
    "section": "",
    "text": "Section instructor: Mark W. Girard\nThis webpage contains some of the information my students in my sections of MATH 173 at the University of Waterloo in Fall 2020."
  },
  {
    "objectID": "academic/teaching/math137_2020/index.html#solutions-to-homework-assignments",
    "href": "academic/teaching/math137_2020/index.html#solutions-to-homework-assignments",
    "title": "MATH 137: Calculus I Honours (Fall 2020)",
    "section": "Solutions to homework assignments",
    "text": "Solutions to homework assignments\nThe solutions provided by the course coordinator were not very clear or written very well. To help you improve your proof-writing techniques, I wrote up a collection of nicely written solutions to the homework assignments in a proper way.\nYou can find the solutions (along with good proof-writing tips) here."
  },
  {
    "objectID": "academic/teaching/math137_2020/index.html#final-exam-practice",
    "href": "academic/teaching/math137_2020/index.html#final-exam-practice",
    "title": "MATH 137: Calculus I Honours (Fall 2020)",
    "section": "Final Exam Practice",
    "text": "Final Exam Practice\nNote: These files are intended to provide you help to do some practice to prepare for the final exam for this course, but do not necessarily reflect the specific problems that will appear on your exam.\n\nPractice problems\nI made a collection of practice problems to help you prepare.\n\nHere are the practice problems\nHere are the solutions are the solutions.\n\n\n\nExams from previous terms\nHere are some final exams from previous years with solutions.\n\nFall 2018 [Exam and solutions]\nFall 2019 [Exam and solutions]"
  },
  {
    "objectID": "academic/teaching/index.html",
    "href": "academic/teaching/index.html",
    "title": "Teaching",
    "section": "",
    "text": "This page serves as an archive of courses I taught during my academic career. It includes syllabi, lecture notes, and problem sets where available, organized by institution.\n\n\nUniversity of Waterloo\n\n\n\nTerm\nCourse Code(s)\nTitle\nMaterials\n\n\n\n\nFall 2021\nMATH 135\nAlgebra for Honours Mathematics\nView page\n\n\nFall 2020\nMATH 137\nCalculus I Honours\nView page\n\n\nFall 2019\nMATH 212 / ECE 206\nAdvanced Calculus 2 for Electrical Engineers\nView page\n\n\nSpring 2019\nMATH 117\nCalculus I for Engineers\n(Page not archived)\n\n\nSpring 2018\nMATH 212 / ECE 206\nAdvanced Calculus 2 for Electrical Engineers\n(Page not archived)\n\n\n\n\n\nUniversity of Calgary\n\n\n\nTerm\nCourse Code\nTitle\nMaterials\n\n\n\n\nSummer 2016\nMATH 271\nDiscrete Mathematics\nView page"
  },
  {
    "objectID": "academic/teaching/271/index.html",
    "href": "academic/teaching/271/index.html",
    "title": "MATH 271 (Summer 2016)",
    "section": "",
    "text": "Discrete Mathematics\nDepartment of Mathematics and Statistics, University of Calgary"
  },
  {
    "objectID": "academic/teaching/271/index.html#course-information",
    "href": "academic/teaching/271/index.html#course-information",
    "title": "MATH 271 (Summer 2016)",
    "section": "Course information",
    "text": "Course information\nThis is the webpage for MATH 271 taught during the 2016 Summer term. We will use the following textbook for the course: Discrete Mathematics with Applications, 4th edition, by Susanna Epp.\nCourse information (Note: the office is incorrectly listed on this document. My office is located at MS 336.)\nInstructor: Mark Girard\nSchedule: tentative schedule\nTime and Location:\n\nLectures: MWF 10:00-11:50 in SA 106\nOffice hours: MWF 9:00-9:50 in MS 336.\nLabs/tutorials. Times: MW 12:00-12:50 and TR 10:00-10:50.\n\nLab section 1. Room: MS 217. TA: Zachary Moyer.\nLab section 2. Room: MS 211. TA: Sumin Leem."
  },
  {
    "objectID": "academic/teaching/271/index.html#practice-problems",
    "href": "academic/teaching/271/index.html#practice-problems",
    "title": "MATH 271 (Summer 2016)",
    "section": "Practice Problems",
    "text": "Practice Problems\n\n\n\nWeek\nProblems\nSolutions\n\n\n\n\nWeek 1\nProblems\nSolutions\n\n\nWeek 2\nProblems\nSolutions\n\n\nWeek 3\nProblems\nSolutions\n\n\nWeek 4\nProblems\nSolutions\n\n\nWeek 5\nProblems\nSolutions\n\n\nWeek 6\nProblems\nSolutions\n\n\nWeek 6 (extra: graph theory)\nExtra Problems\nSolutions"
  },
  {
    "objectID": "academic/teaching/271/index.html#assignments",
    "href": "academic/teaching/271/index.html#assignments",
    "title": "MATH 271 (Summer 2016)",
    "section": "Assignments",
    "text": "Assignments\nAssignments are due at 10:00am on the due date. Hand your solutions in to your TA by the beginning of lab.\n\n\n\nAssignment (pdf)\nDue date\nSolutions (pdf)\n\n\n\n\nAssignment 1\nJuly 19\nsolutions\n\n\nAssignment 2\nJuly 26\nsolutions\n\n\nAssignment 3\nAugust 9\nsolutions\n\n\nAssignment 4\nAugust 16\nsolutions"
  },
  {
    "objectID": "academic/teaching/271/index.html#quizzes",
    "href": "academic/teaching/271/index.html#quizzes",
    "title": "MATH 271 (Summer 2016)",
    "section": "Quizzes",
    "text": "Quizzes\n\n\n\nQuiz (pdf)\nDate\nMaterial\nSolutions\n\n\n\n\nQuiz 1\nJuly 14\nStatements and negation (for all, exists, if-then, converse, contrapositive), even/odd integers, divisibility, direct proofs\nsolutions\n\n\nQuiz 2\nJuly 21\nProof by contradiction, rational and irrational numbers, gcd (Euclidean algorithm), induction\nsolutions\n\n\nQuiz 3\nJuly 28\nStrong induction, sets (element method)\nsolutions\n\n\nQuiz 4\nAugust 11\nCounting (permutations, combinations, inclusion/exclusion principle) and functions (one-to-one, onto, function composition)\nsolutions"
  },
  {
    "objectID": "academic/teaching/271/index.html#midterm",
    "href": "academic/teaching/271/index.html#midterm",
    "title": "MATH 271 (Summer 2016)",
    "section": "Midterm",
    "text": "Midterm\nThe midterm will be on Friday August 5, in class (during the lecture period) from 10:00-11:50am.\nThe midterm will cover all of the course material up to section 9.3.\nPrevious midterms (solutions will be posted a few days before the midterm date)\n\n2011-2014 and solutions\n2015 (winter term) and solutions\n2016 (winter term) and solutions\n\nUpdate Here is the midterm and solutions."
  },
  {
    "objectID": "academic/teaching/271/index.html#final",
    "href": "academic/teaching/271/index.html#final",
    "title": "MATH 271 (Summer 2016)",
    "section": "Final",
    "text": "Final\nThe the final exam will be on Friday, August 19 at 8:00am in room ES 162.\nThe exam will cover all of the course material (up to section 10.2). Here is a list of study topics for the final exam for your studying.\nPrevious final exams and solutions for you to practice can be found here:\n\nW2011 final and solutions\nW2012 final and solutions\nW2013 final and solutions\nW2014 final and solutions"
  },
  {
    "objectID": "academic/coursework/index.html",
    "href": "academic/coursework/index.html",
    "title": "Graduate Coursework Archive",
    "section": "",
    "text": "This page archives some of my graduate coursework from the University of Calgary.\nMost of these course notes were “live-TeXed,” meaning I typed them up on my laptop during lectures. I make no guarantee of their accuracy — there are likely typos, gaps, or mathematical errors. I also make no guarantee on the correctness of my solutions to the assigned problems.\nThat said, others have found them useful over the years, so I’m sharing them here publicly in the spirit of open learning.\n\n\nMATH 667 – Quantum Information Theory\nTaught by Gilad Gour, Winter Semester 2016\nThis course introduced the mathematical foundations of quantum computing and information theory. Topics included quantum states, density operators, quantum channels, entropy, and coding theorems.\n\n\n\nTitle\nType\nLink\n\n\n\n\nLecture Notes\nNotes\nDownload PDF\n\n\nAssignment 2\nHomework\nDownload PDF\n\n\n\n\n\n\nMATH 621 – Complex Analysis\nTaught by Alex Brudnyi, Fall Semester 2014\nThis course covered advanced topics in complex analysis, including contour integration, Cauchy’s theorem, Laurent series, and the residue theorem.\nAll assignment problems were taken from Complex Analysis by Theodore Gamelin.\n\n\n\nTitle\nType\nLink\n\n\n\n\nAssignment 1\nHomework\nDownload PDF\n\n\nAssignment 2\nHomework\nDownload PDF\n\n\nAssignment 3\nHomework\nDownload PDF\n\n\nMidterm\nExam\nDownload PDF\n\n\nAssignment 4\nHomework\nDownload PDF\n\n\nAssignment 5\nHomework\nDownload PDF\n\n\nFinal Problem Set\nProblem Set\nDownload PDF\n\n\n\n\n\n\nPMAT 617 – Algebra IV\nTaught by Clifton Cunningham, Winter Semester 2014\nThis abstract algebra course focused on module theory, tensor products, exact sequences, and homological algebra.\nAll assignment roblems were taken from Algebra: Chapter 0 by Paolo Aluffi.\n\n\n\nTitle\nType\nLink\n\n\n\n\nLecture Notes\nNotes\nDownload PDF\n\n\nAssignment 1\nHomework\nDownload PDF\n\n\nAssignment 2\nHomework\nDownload PDF\n\n\nAssignment 3\nHomework\nDownload PDF\n\n\nAssignment 4\nHomework\nDownload PDF\n\n\nAssignment 5\nHomework\nDownload PDF\n\n\nFinal Exam Review\nReview\nDownload PDF\n\n\n\n\n\n\nAMAT 617 – Functional Analysis\nTaught by Gilad Gour, Winter Semester 2014\nThis course covered the theory of normed vector spaces, inner product spaces, Hilbert spaces, and operators, with applications to analysis and PDEs.\nAll assignment problems were taken from Introductory Functional Analysis with Applications by Erwin Kreyszig.\n\n\n\nTitle\nType\nLink\n\n\n\n\nLecture Notes\nNotes\nDownload PDF\n\n\nAssignment 1\nHomework\nDownload PDF\n\n\nAssignment 2\nHomework\nDownload PDF\n\n\nAssignment 3\nHomework\nDownload PDF\n\n\nAssignment 4\nHomework\nDownload PDF\n\n\nAssignment 5\nHomework\nDownload PDF\n\n\nFinal Exam Review\nReview\nDownload PDF"
  },
  {
    "objectID": "academic/academic.html",
    "href": "academic/academic.html",
    "title": "Academic Archive",
    "section": "",
    "text": "Before transitioning to industry, I spent many years immersed in the academic world of mathematics and physics — studying, researching, and teaching in both Canada and abroad.\nThis page gathers some of the materials from that part of my life — a kind of archive for the mathematically curious."
  },
  {
    "objectID": "academic/academic.html#curriculum-vitae",
    "href": "academic/academic.html#curriculum-vitae",
    "title": "Academic Archive",
    "section": "Curriculum Vitae",
    "text": "Curriculum Vitae\nMy academic journey included study and research across several institutions:\n\nB.Sc. in Mathematics, Physics, and German — Trinity University (San Antonio, Texas), 2006–2010\n\nDiplom in Physics — University of Freiburg, Germany, 2010–2012\nThesis: Optimal Control of Many-Body Entanglement with Measures Optimized on the Fly\nPh.D. in Applied Mathematics — University of Calgary, 2012–2017\nThesis: Convex Analysis for Quantum Information Theory\nAdviser: Gilad Gour\nPostdoctoral Fellow — Institute for Quantum Computing, University of Waterloo, 2017–2020\n\nSessional Instructor — Faculty of Mathematics, University of Waterloo, 2018–2020\n(Also taught one course at the University of Calgary in 2016)\n\nYou can download the full version of my academic CV here:\nDownload CV (PDF)"
  },
  {
    "objectID": "academic/academic.html#teaching",
    "href": "academic/academic.html#teaching",
    "title": "Academic Archive",
    "section": "Teaching",
    "text": "Teaching\nFrom introductory calculus to upper-level analysis, I taught a range of undergraduate courses at both the University of Waterloo and the University of Calgary. This section includes syllabi, assignments, lecture notes, and more.\n👉 Teaching Archive"
  },
  {
    "objectID": "academic/academic.html#graduate-coursework",
    "href": "academic/academic.html#graduate-coursework",
    "title": "Academic Archive",
    "section": "Graduate Coursework",
    "text": "Graduate Coursework\nTyped lecture notes and homework solutions from my graduate studies at the University of Calgary. Topics include quantum information theory, functional analysis, complex analysis, and algebra.\n👉 Coursework Archive"
  },
  {
    "objectID": "academic/academic.html#publications",
    "href": "academic/academic.html#publications",
    "title": "Academic Archive",
    "section": "Publications",
    "text": "Publications\nA list of my peer-reviewed research publications and preprints, mostly in quantum information theory.\n👉 Publications"
  },
  {
    "objectID": "academic/publications.html",
    "href": "academic/publications.html",
    "title": "Publications",
    "section": "",
    "text": "Below is a list of my peer-reviewed research publications in quantum information theory."
  },
  {
    "objectID": "academic/publications.html#peer-reviewed-publications",
    "href": "academic/publications.html#peer-reviewed-publications",
    "title": "Publications",
    "section": "Peer-Reviewed Publications",
    "text": "Peer-Reviewed Publications\n\n\n\nYear\nTitle\nJournal\nDOI\narXiv\n\n\n\n\n2022\nOn the mixed-unitary rank of quantum channelsM. Girard, D. Leung, J. Levick, C.-K. Li, V. Paulsen, Y.-T. Poon, J. Watrous\nCommunications in Mathematical Physics, 394(2), 919–951\n10.1007/s00220-022-04412-y\n2003.14405\n\n\n2021\nCertifying optimality for convex quantum channel optimization problemsB. Coutts, M. Girard, J. Watrous\nQuantum, 5, 448\n10.22331/q-2021-05-01-448\n1810.13295\n\n\n2021\nTwirling channels have minimal mixed-unitary rankM. Girard, J. Levick\nLinear Algebra and its Applications, 615, 207–227\n10.1016/j.laa.2020.12.027\n2005.07056\n\n\n2021\nJordan products of quantum channels and their compatibilityM. Girard, M. Plávala, J. Sikora\nNature Communications, 12, 2129\n10.1038/s41467-021-22275-0\n2009.03279\n\n\n2021\nConvex cones in mapping spaces between matrix algebrasM. Girard, S.-H. Kye, E. Størmer\nLinear Algebra and its Applications, 608, 248–269\n10.1016/j.laa.2020.08.017\n2001.11166\n\n\n2017\nEntanglement monotones and transformations of symmetric bipartite statesM. W. Girard, G. Gour\nPhysical Review A, 95, 012308\n10.1103/PhysRevA.95.012308\n1609.08016\n\n\n2015\nComputable entanglement conversion witness that is better than the negativityM. W. Girard, G. Gour\nNew Journal of Physics, 17, 093013\n10.1088/1367-2630/17/9/093013\n1410.7094\n\n\n2015\nErratum: Numerical estimation of the relative entropy of entanglementM. W. Girard, Y. Zinchenko, S. Friedland, G. Gour\nPhysical Review A, 91, 029901\n10.1103/PhysRevA.91.029901\n—\n\n\n2014\nOn convex optimization problems in quantum information theoryM. W. Girard, G. Gour, S. Friedland\nJournal of Physics A: Mathematical and Theoretical, 47, 505302\n10.1088/1751-8113/47/50/505302\n1402.0034\n\n\n2012\nGradient-based stopping rules for maximum-likelihood quantum-state tomographyS. Glancy, E. Knill, M. Girard\nNew Journal of Physics, 14, 095017\n10.1088/1367-2630/14/9/095017\n1205.4043"
  },
  {
    "objectID": "academic/publications.html#theses",
    "href": "academic/publications.html#theses",
    "title": "Publications",
    "section": "Theses",
    "text": "Theses\n\nPh.D. Thesis (2017): Convex Analysis in Quantum Information\nUniversity of Calgary.\nFull text\nDiplom Thesis (2012): Optimal Control of Many-Body Entanglement with Measures Optimized on the Fly\nUniversity of Freiburg.\nFull text"
  },
  {
    "objectID": "academic/teaching/ece206_2019/index.html",
    "href": "academic/teaching/ece206_2019/index.html",
    "title": "ECE 206 (Fall 2019)",
    "section": "",
    "text": "University of Waterloo\n\n\nThis is the webpage for ECE 206 taught during the 2019 Fall term.\nSyllabus and course schedule: Syllabus\nInstructor: Mark Girard [email: m4girard@uwaterloo.ca]\nTA: Zhibing Sun [email: zhibing@uwaterloo.ca]\nTime and Location:\n\nLectures: Tues/Wed/Thurs 15:30-16:20 in E7 4417\nLabs/tutorials. Wed 17:30-18:20 in E7 4433\nOffice hours: 9:00-10:00 on Mondays and 12:00-13:00 Wednesdays (or by appointment).\n\nAdditional makeup lectures are scheduled Thurs 12:30-13:20 in E7 4417 for the following dates:\n\nSep 12, Sep 26, Oct 10, Oct 31, Nov 14, Nov 28.\n\n\n\n\n\n\n\nLecture Notes\nLecture Dates\nTutorial / Quizzes\nPractice Problems\nSolutions\n\n\n\n\nWeek 0\n\n\n\n\n\n\nWeek 1\nSeptember 4 and 5\n(no tutorial)\nProblems Week 1\nSolutions\n\n\nWeek 2\nSeptember 10–12 (+makeup)\n\nProblems Week 2\nSolutions\n\n\nWeek 3\nSeptember 17–19\nQuiz 1\nProblems Week 3\nSolutions\n\n\nWeek 4\nSeptember 24–26 (+makeup)\nQuiz 2 (Sept 26)\nProblems Week 4\nSolutions\n\n\nWeek 5\nOctober 1–3\n\nProblems Week 5\nSolutions\n\n\nWeek 6\nOctober 8–10 (+makeup)\nQuiz 3\nProblems Week 6\nSolutions\n\n\nWeek 7\nReading week\n(no tutorial)\n\n\n\n\nWeek 8\nOctober 29–31 (+makeup)\nQuiz 4 (Oct 31)\nProblems Week 8\nSolutions\n\n\nWeek 9\nNovember 5–7\nQuiz 5\nProblems Week 9\nSolutions\n\n\nWeek 10\nNovember 12–14 (+makeup)\nQuiz 6\nProblems Week 10\nSolutions\n\n\nWeek 11\nNovember 19–21\n\nProblems Week 11\nSolutions\n\n\nWeek 12\nNovember 26–28 (+makeup)\nQuiz 7 (cancelled)\nProblems Week 12\nSolutions\n\n\n\n\n\n\n\n\n\n\nDate (location)\n\n\n\n\n\nQuiz 1\nSept 18 (in tutorial)\nsolutions\n\n\nQuiz 2\nSept 26 (in class)\nsolutions\n\n\nQuiz 3\nOct 9 (in tutorial)\nsolutions\n\n\nQuiz 4\nOct 31 (in tutorial)\nsolutions\n\n\nQuiz 5\nNov 5 (in tutorial)\nsolutions\n\n\nQuiz 6\nNov 13 (in tutorial)\nsolutions\n\n\n\n\n\n\nThe midterm will be on Thursday October 24 at 16:45-19:00 in E7-4417.\nThe midterm will cover all of the course material up to the end of Week 6. Find a list of topics to study here and the formula sheet that will be available here.\nYou can find a previous midterm to help you study here.\n*Update*: Here is the midterm and solutions.\n\n\n\nThe final exam will be on Friday, August 19 at 8:00am in room ES 162.\nThe exam will cover all of the course material.\nHere are a few final exams from previous years.\n\nFall 2017 final and solutions\nSpring 2018 final and solutions\n\n[Warning: Other instructors use different notation/terminology that I do in this course. These exams may not reflect the material that will be covered in this term’s final.]"
  },
  {
    "objectID": "academic/teaching/ece206_2019/index.html#course-information",
    "href": "academic/teaching/ece206_2019/index.html#course-information",
    "title": "ECE 206 (Fall 2019)",
    "section": "",
    "text": "This is the webpage for ECE 206 taught during the 2019 Fall term.\nSyllabus and course schedule: Syllabus\nInstructor: Mark Girard [email: m4girard@uwaterloo.ca]\nTA: Zhibing Sun [email: zhibing@uwaterloo.ca]\nTime and Location:\n\nLectures: Tues/Wed/Thurs 15:30-16:20 in E7 4417\nLabs/tutorials. Wed 17:30-18:20 in E7 4433\nOffice hours: 9:00-10:00 on Mondays and 12:00-13:00 Wednesdays (or by appointment).\n\nAdditional makeup lectures are scheduled Thurs 12:30-13:20 in E7 4417 for the following dates:\n\nSep 12, Sep 26, Oct 10, Oct 31, Nov 14, Nov 28."
  },
  {
    "objectID": "academic/teaching/ece206_2019/index.html#course-schedule",
    "href": "academic/teaching/ece206_2019/index.html#course-schedule",
    "title": "ECE 206 (Fall 2019)",
    "section": "",
    "text": "Lecture Notes\nLecture Dates\nTutorial / Quizzes\nPractice Problems\nSolutions\n\n\n\n\nWeek 0\n\n\n\n\n\n\nWeek 1\nSeptember 4 and 5\n(no tutorial)\nProblems Week 1\nSolutions\n\n\nWeek 2\nSeptember 10–12 (+makeup)\n\nProblems Week 2\nSolutions\n\n\nWeek 3\nSeptember 17–19\nQuiz 1\nProblems Week 3\nSolutions\n\n\nWeek 4\nSeptember 24–26 (+makeup)\nQuiz 2 (Sept 26)\nProblems Week 4\nSolutions\n\n\nWeek 5\nOctober 1–3\n\nProblems Week 5\nSolutions\n\n\nWeek 6\nOctober 8–10 (+makeup)\nQuiz 3\nProblems Week 6\nSolutions\n\n\nWeek 7\nReading week\n(no tutorial)\n\n\n\n\nWeek 8\nOctober 29–31 (+makeup)\nQuiz 4 (Oct 31)\nProblems Week 8\nSolutions\n\n\nWeek 9\nNovember 5–7\nQuiz 5\nProblems Week 9\nSolutions\n\n\nWeek 10\nNovember 12–14 (+makeup)\nQuiz 6\nProblems Week 10\nSolutions\n\n\nWeek 11\nNovember 19–21\n\nProblems Week 11\nSolutions\n\n\nWeek 12\nNovember 26–28 (+makeup)\nQuiz 7 (cancelled)\nProblems Week 12\nSolutions"
  },
  {
    "objectID": "academic/teaching/ece206_2019/index.html#quizzes",
    "href": "academic/teaching/ece206_2019/index.html#quizzes",
    "title": "ECE 206 (Fall 2019)",
    "section": "",
    "text": "Date (location)\n\n\n\n\n\nQuiz 1\nSept 18 (in tutorial)\nsolutions\n\n\nQuiz 2\nSept 26 (in class)\nsolutions\n\n\nQuiz 3\nOct 9 (in tutorial)\nsolutions\n\n\nQuiz 4\nOct 31 (in tutorial)\nsolutions\n\n\nQuiz 5\nNov 5 (in tutorial)\nsolutions\n\n\nQuiz 6\nNov 13 (in tutorial)\nsolutions"
  },
  {
    "objectID": "academic/teaching/ece206_2019/index.html#midterm",
    "href": "academic/teaching/ece206_2019/index.html#midterm",
    "title": "ECE 206 (Fall 2019)",
    "section": "",
    "text": "The midterm will be on Thursday October 24 at 16:45-19:00 in E7-4417.\nThe midterm will cover all of the course material up to the end of Week 6. Find a list of topics to study here and the formula sheet that will be available here.\nYou can find a previous midterm to help you study here.\n*Update*: Here is the midterm and solutions."
  },
  {
    "objectID": "academic/teaching/ece206_2019/index.html#final",
    "href": "academic/teaching/ece206_2019/index.html#final",
    "title": "ECE 206 (Fall 2019)",
    "section": "",
    "text": "The final exam will be on Friday, August 19 at 8:00am in room ES 162.\nThe exam will cover all of the course material.\nHere are a few final exams from previous years.\n\nFall 2017 final and solutions\nSpring 2018 final and solutions\n\n[Warning: Other instructors use different notation/terminology that I do in this course. These exams may not reflect the material that will be covered in this term’s final.]"
  },
  {
    "objectID": "academic/teaching/math135_2021/index.html",
    "href": "academic/teaching/math135_2021/index.html",
    "title": "MATH 135: Algebra for Honours Mathematics",
    "section": "",
    "text": "University of Waterloo — Fall 2021\nSection instructor: Mark W. Girard\nThese materials were created to supplement the shared course resources.\n\n\n\nPractice Problems\nEach problem set was written in LaTeX and compiled with and without solutions.\n\n\n\nChapter(s)\nProblems (PDF)\nWith Solutions (PDF)\nLaTeX Source\n\n\n\n\nChapter 4: Induction\nDownload\nDownload\nTeX\n\n\nChapter 5: Sets\nDownload\nDownload\nTeX\n\n\nChapters 6–8: GCD & Division\nDownload\nDownload\nTeX\n\n\nChapter 9: RSA Encryption\nDownload\nDownload\nTeX\n\n\nChapters 9–10: Complex numbers and Polynomials\nDownload\nDownload\nTeX\n\n\n\n\n\n\nSample Proofs from Lectures\nThe following lecture slides illustrate various proof techniques taught in the course. Each includes both the compiled PDF shown in class and the original LaTeX source.\n\n\n\nLecture #\nTopic\nPDF\nLaTeX Source\n\n\n\n\n5\nProving equalities, inequalities, cases\nLecture 5\nTeX\n\n\n6\nExistential proofs, negation, implications\nLecture 6\nTeX\n\n\n8\nContrapositive, elimination, iff\nLecture 8\nTeX\n\n\n9\nContradiction, uniqueness\nLecture 9\nTeX\n\n\n10\nInduction\nLecture 10\nTeX\n\n\n11\nStrong induction, recursive sequences\nLecture 11\nTeX\n\n\n12\nGame proofs — Chomp\nLecture 12\nTeX\n\n\n\n\n\nVisualizing the GCD\nThis PDF was shown in class to help visualize the Euclidean algorithm for computing the GCD.\n\nEuclid Visualization"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "A collection of math musings, Riddler puzzle solutions, and occasional thoughts.\n\n\n\n\n\n\n\n\n  \n\n\n\n\nRiddler: Tackling the blind letter challenge — Can You Defeat The TikTok Meme?\n\n\n\n\n\n\n\nriddler\n\n\nprogramming\n\n\n\n\nOn optimal strategies in a TikTok-inspired puzzle game.\n\n\n\n\n\n\nJan 27, 2023\n\n\nMark Girard\n\n\n\n\n\n\n  \n\n\n\n\nRiddler: As the drone flies — Can you make a speedy delivery?\n\n\n\n\n\n\n\ngeometry\n\n\nriddler\n\n\n\n\nCalculating expected distances under different city travel metrics.\n\n\n\n\n\n\nJan 23, 2023\n\n\nMark Girard\n\n\n\n\n\n\n  \n\n\n\n\nRandom Infinite Graphs\n\n\n\n\n\n\n\nmathematics\n\n\ncombinitorics\n\n\n\n\nA deep dive into universality of infinite random graphs.\n\n\n\n\n\n\nJan 3, 2023\n\n\nMark Girard\n\n\n\n\n\n\n  \n\n\n\n\nRiddler: The Riddler Gift Exchange?\n\n\n\n\n\n\n\ncombinitorics\n\n\nriddler\n\n\n\n\nHow many gifts survive in a white elephant exchange with random rules?\n\n\n\n\n\n\nDec 16, 2022\n\n\nMark Girard\n\n\n\n\n\n\n  \n\n\n\n\nRiddler: What are the odds of a solo win in Mexican bingo?\n\n\n\n\n\n\n\nriddler\n\n\nprobability\n\n\n\n\nSolving a probability puzzle involving a Mexican-themed draw.\n\n\n\n\n\n\nOct 21, 2022\n\n\nMark Girard\n\n\n\n\n\n\n  \n\n\n\n\nRiddler: How big is your birthday surprise party?\n\n\n\n\n\n\n\nprogramming\n\n\nriddler\n\n\nprobability\n\n\n\n\nModeling birthday collisions in a unique gift-sharing game.\n\n\n\n\n\n\nOct 14, 2022\n\n\nMark Girard\n\n\n\n\n\n\n  \n\n\n\n\nRiddler: Anigrams\n\n\n\n\n\n\n\nriddler\n\n\npuzzles\n\n\n\n\nA probability puzzle involving rare letter permutations.\n\n\n\n\n\n\nSep 16, 2022\n\n\nMark Girard\n\n\n\n\n\n\n  \n\n\n\n\nRiddler: Overlapping Disks\n\n\n\n\n\n\n\nriddler\n\n\npuzzles\n\n\n\n\nA geometry puzzle about overlapping three disks.\n\n\n\n\n\n\nSep 9, 2022\n\n\nMark Girard\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/2022-09-16-riddler-anigrams.html",
    "href": "blog/posts/2022-09-16-riddler-anigrams.html",
    "title": "Riddler: Anigrams",
    "section": "",
    "text": "My solution to this week’s riddler. (See more of my Riddler solutions here.)"
  },
  {
    "objectID": "blog/posts/2022-09-16-riddler-anigrams.html#the-problem",
    "href": "blog/posts/2022-09-16-riddler-anigrams.html#the-problem",
    "title": "Riddler: Anigrams",
    "section": "The Problem",
    "text": "The Problem\nFrom Michael Branicky comes a word puzzle that is the G.O.A.T.:\n\nIf you like Wordle, then you might also enjoy Anigrams, a game created by Friend-of-the-Riddler™ Adam Wagner.\nIn the game of Anigrams, you unscramble successively larger, nested collections of letters to create a valid “chain” of six English words between four and nine letters in length.\nFor example, a chain of five words (sadly, less than the six needed for a valid game of Anigrams) can be constructed using the following sequence, with each term after the first including one additional letter than the previous term:\n\nDEIR (which unscrambles to make the words DIRE, IRED or RIDE)\nDEIRD (DRIED or REDID)\nDEIRDL (DIRLED, DREIDL or RIDDLE)\nDEIRDLR (RIDDLER)\nDEIRDLRS (RIDDLERS)\n\nWhat is the longest chain of such nested anagrams you can create, starting with four letters?\nFor specificity, all valid words must come from Peter Norvig’s word list (a list we’ve used previously here at The Riddler).\nExtra credit: How many possible games of Anigrams games are there? That is, how many valid sets are there of four initial letters, and then five more letters added one at a time in an ordered sequence, that result in a sequence of valid anagrams? (Note: Swapping the order of the first four letters does not result in a distinct game.)"
  },
  {
    "objectID": "blog/posts/2022-09-16-riddler-anigrams.html#the-solution",
    "href": "blog/posts/2022-09-16-riddler-anigrams.html#the-solution",
    "title": "Riddler: Anigrams",
    "section": "The Solution",
    "text": "The Solution\nIt turns out that the longest such chain of anagrams has length 13. While there are numerous such chains, one possible chain of length 13 is given by:\n\naeno\naenos\naenost\naeinost\naeimnost\naeimnnost\naeiimnnost\naeiimnnorst\naeiimnnorstt\nadeiimnnorstt\nadeeiimnnorstt\nadeeiiimnnorstt\nadeeiiimnnnorstt\n\nWith one possible solution being:\n\naeon\naeons\natones\natonies\namniotes\nnominates\nantimonies\ninseminator\nterminations\nantimodernist\ndeterminations\nintermediations\nindeterminations\n\n(Interstingly, every anigram chain of lenth 13 ends in the same 6 words: inseminator, terminations, antimodernist, determinations, intermediations, indeterminations.)\n\nExtra credit:\nAssuming a valid anigram game starts with 4 letters and ends with 10 letters, there are 8,660,949 distinct anigram games.\nI wrote up some code to compute my answer which you can see below:\nfrom urllib.request import urlopen\nfrom collections import defaultdict\nfrom functools import lru_cache\n\n\nurl = \"https://norvig.com/ngrams/enable1.txt\"\nfile = urlopen(url)\nwords = [line.decode(\"utf-8\").strip() for line in file]\n\nalphabet = 'abcdefghijklmnopqrstuvwxyz'\n\ndef main():\n    anagrams = defaultdict(list)\n    for word in words:\n        # Ignore words of length less than 4\n        # (short words are not used in this problem)\n        if len(word) &gt;= 4:\n            anagrams[''.join(sorted(word))].append(word)\n\n    # An anagram is a child of another anagram if one letter can be added to\n    # the parent anagram to produce the child anagram.\n    graph = defaultdict(list)\n    for anagram in anagrams:\n        for letter in alphabet:\n            child = ''.join(sorted(anagram + letter))\n            if child in anagrams:\n                graph[anagram].append(child)\n\n    @lru_cache(maxsize=None)\n    def get_longest_chain(anagram):\n        if len(graph[anagram]) == 0:\n            return (anagram,)\n        anigrams = [get_longest_chain(child) for child in graph[anagram]]\n        return (anagram,) + max(anigrams, key=len)\n\n    start_anagrams = [anagram for anagram in anagrams if len(anagram) == 4]\n\n    longest_chain = (\n        max(\n            (get_longest_chain(anagram) for anagram in start_anagrams),\n            key=len\n        )\n    )\n\n    print(f\"The longest chain has length {len(longest_chain)}\")\n\n    outstring = \"\"\"\nThere are numerous ways to construct an anigram chain with this length, but\none such chain is given by:\n\"\"\"\n    print(outstring)\n    for anagram in longest_chain:\n        print(\"- \" + anagram)\n\n    print(\"With one possible solution being:\")\n    for anagram in longest_chain:\n        print(\"- \" + anagrams[anagram][0])\n\n    def count_anigram_games():\n        @lru_cache(maxsize=None)\n        def count_anigrams(anagram):\n            if len(anagram) == 10:\n                return 1\n            return sum(count_anigrams(child) for child in graph[anagram])\n\n        ans = (\n            sum(count_anigrams(anagram)\n                for anagram in anagrams if len(anagram) == 4)\n        )\n        return ans\n\n    num_anigram_games = count_anigram_games()\n\n    print(\"\"\"\nExtra credit:\nAssuming a valid anigram game starts with 4 letters and ends with 10 letters:\nthere are {num_anigram_games} distinct anigram games.\n\"\"\".format(num_anigram_games=num_anigram_games)\n)\n\n\nif __name__ == '__main__':\n    main()"
  },
  {
    "objectID": "blog/posts/2022-10-21-mexican-lottery.html",
    "href": "blog/posts/2022-10-21-mexican-lottery.html",
    "title": "Riddler: What are the odds of a solo win in Mexican bingo?",
    "section": "",
    "text": "My solution to this week’s riddler. (See more of my Riddler solutions here.)"
  },
  {
    "objectID": "blog/posts/2022-10-21-mexican-lottery.html#the-problem",
    "href": "blog/posts/2022-10-21-mexican-lottery.html#the-problem",
    "title": "Riddler: What are the odds of a solo win in Mexican bingo?",
    "section": "The Problem",
    "text": "The Problem\nFrom Roberto Linares comes a puzzle that will have you shouting “Bingo!”:\n\nA thousand people are playing Lotería, also known as Mexican bingo. The game consists of a deck of 54 cards, each with a unique picture. Each player has a board with 16 of the 54 pictures, arranged in a 4-by-4 grid. The boards are randomly generated, such that each board has 16 distinct pictures that are equally likely to be any of the 54.\nDuring the game, one card from the deck is drawn at a time, and anyone whose board includes that card’s picture marks it on their board. A player wins by marking four pictures that form one of four patterns, as exemplified below: any entire row, any entire column, the four corners of the grid and any 2-by-2 square. \nFour four-by-four grids are shown. In the first grid, the third row has four blue markers. In the second grid, the second column has four blue markers. In the third grid, the four corner squares are marked. And in the fourth grid, the two middle squares in the third and fourth columns are marked, forming a smaller two-by-two square.\nAfter the fourth card has been drawn, there are no winners. What is the probability that there will be exactly one winner when the fifth card is drawn?"
  },
  {
    "objectID": "blog/posts/2022-10-21-mexican-lottery.html#the-solution",
    "href": "blog/posts/2022-10-21-mexican-lottery.html#the-solution",
    "title": "Riddler: What are the odds of a solo win in Mexican bingo?",
    "section": "The Solution",
    "text": "The Solution\nThis is a pretty simple counting and probability problem. Let \\(p_4\\) and \\(p_5\\) be the probabilities that a given board wins after exactly \\(4\\) or \\(5\\) draws, respectively. The probability that we are seeking is therefore\n\\[\nP = \\operatorname{Pr}\\big(\\text{exactly one winner after 5 draws }\\big|\\text{ no winners after 4 draws}\\big) = \\frac{1000p_5(1-p_4-p_5)^{999}}{(1-p_4)^{1000}}\n\\]\nIt remains to determine \\(p_4\\) and \\(p_5\\). The total number of ways that the first 4 cards can be drawn is simply equal to\n\\[\nn_4 = 54\\cdot53\\cdot52\\cdot 51.\n\\]\nFor a given board, we can count the number of ways in which the first 4 cards can be drawn that lead to that board winning as follows. First note that there are 18 distinct winning patterns:\n\n4 distinct columns\n4 distinct rows\n9 distinct 2x2 blocks\n1 set of all four corners\n\nTo count the number of ways in which a board wins after 4 draws, first pick one of the 18 distinct ways in which that board can win. For the board to win with that pattern, the cards with the four pictures on the four squares composing that pattern must be the first 4 cards that are drawn, in any possible order. Hence there are \\(18\\cdot 4!\\) ways that the first 4 cards can be drawn that lead to a given board winning, and thus\n\\[\np_4 = \\frac{18\\cdot 4!}{54\\cdot53\\cdot52\\cdot 51} = \\frac{2}{35139} \\approx 0.000056916.\n\\]\nThe number of ways that a board can win after exactly 5 draws is exactly 4 times the number of boards that win after exactly 4 draws. That is,\n\\[\np_5 = 4p_4.\n\\]\nTo see this, note that after 5 draws any valid board can only have at most one of the 18 winning patterns completely filled in. As above, to count the number of ways that a board wins after 5 draws, first pick one of the 18 distinct patterns from above. Of the first 4 cards drawn, exactly one of them cannot match a picture in the four squares comprising the winning pattern (and there are 4 ways this can happen). The 4 cards that do match the pictures in the winning pattern can otherwise be drawn in any order, and thus\n\\[\np_5 = 18\\cdot 4\\cdot 4! = 4p_4.\n\\]\nThe probability in question can therefore be computed as\n\\[\nP = \\frac{1000(4p)(1-5p)^{999}}{(1-p)^{1000}} = 0.1813563126414745,\n\\]\nwhere \\(p=p_4 = 2/35139\\). Thus the odds of having exactly one winner after the fifth draw, given that there are 1000 players and no winners after the fourth draw, is about 18.1%.\n\nMore players? More winners?\nWhat happens when there are more players? Does this probability go up or down?\nLet \\(N\\) be the number of players (where \\(N=1000\\) in the original problem statement), each with a randomly selected board. The probability that there are exactly \\(k\\) winners after 5 draws given that there were no winners after 4 draws is computed as\n\\[\n\\begin{align*}\n\\operatorname{Pr}&\\big(\\text{exactly }k\\text{ winners after 5 draws }\\big|\\text{ no winners after 4 draws}\\big)\\\\\n&= \\frac{\\binom{N}{k}(4p)^k(1-5p)^{N-k}}{(1-p)^{N}}\n\\end{align*}\n\\]\nAs the number of players grows, this probability increases to roughly 36.8% at \\(N=4293\\), after which this probability starts to shrink (the probability of there being multiple winners begins to outstrip the probability of there being exactly one winner). The plot below shows the probabilities of having exactly \\(k\\) winners after the fifth draw as the number \\(N\\) of participants grows, given that there are no winners after the fourth draw.\n\n\n\nProbability of exactly k winners after 5 draws as a function of the number of participants, given that there are no winners after 4 draws."
  },
  {
    "objectID": "blog/posts/2023-01-03-random-infinite-graphs.html",
    "href": "blog/posts/2023-01-03-random-infinite-graphs.html",
    "title": "Random Infinite Graphs",
    "section": "",
    "text": "I picked up a book at a used book store recently: Probabilistic Methods in Combinitorics (1974) by Paul Erdős and Joel Spencer. Always a sucker for neat-looking old math books, I picked it up and browse through it ocassionally.\nAs with most of Erdős’ writing, I found the statements and proofs in the book rather obtuse. To help me understand some of the contents, I wanted to write some blog posts as I read through it.\nThe first topic I wanted to look at was a simple one: random infinite graphs. Here, Spencer and Erdős consider randomly generated graphs whose sets of vertices are the natural numbers. Something interesting happens with the graphs generated this way. Namely, they are almost always the same! Up to isomorphism, at least."
  },
  {
    "objectID": "blog/posts/2023-01-03-random-infinite-graphs.html#background",
    "href": "blog/posts/2023-01-03-random-infinite-graphs.html#background",
    "title": "Random Infinite Graphs",
    "section": "Background",
    "text": "Background\nRecall that a graph \\(G\\) is an ordered pair \\((V,E)\\) consisting of a set \\(V\\) of vertices and a set of edges\n\\[\nE\\subseteq\\binom{V}{2}\n\\]\n(where we recall that given a set \\(S\\) and an integer \\(k\\), the notation \\(\\binom{S}{k}\\) is used to denote the collection of all subsets of \\(S\\) containing exactly \\(k\\) elements). We may write \\(\\operatorname{Vertices}(G)=V\\) and \\(\\operatorname{Edges}(G)=E\\). Two distinct vertices \\(a,b\\in \\operatorname{Vertices}(G)\\) are said to be adjacent in \\(G\\) if it holds that\n\\[\n\\lbrace a,b\\rbrace \\in \\operatorname{Edges}(G)\n\\]\nand not adjacent otherwise.\nTwo graphs \\(G\\) and \\(H\\) are said to be isomorphic if there exists a bijection\n\\[\nf:\\operatorname{Vertices}(G)\\to\\operatorname{Vertices}(H)\n\\]\nwith the property that, for every choice of distinct pairs of vertices \\(a,b\\in\\operatorname{Vertices}(G)\\), we have the equivalence\n\\[\n\\lbrace a,b\\rbrace \\in \\operatorname{Edges}(G)\\iff\\lbrace f(a),f(b)\\rbrace \\in \\operatorname{Edges}(H).\n\\]\nGraph isomorphism defines an equivalence relation on a collection of graphs."
  },
  {
    "objectID": "blog/posts/2023-01-03-random-infinite-graphs.html#infinite-graphs-and-universality",
    "href": "blog/posts/2023-01-03-random-infinite-graphs.html#infinite-graphs-and-universality",
    "title": "Random Infinite Graphs",
    "section": "Infinite graphs and universality",
    "text": "Infinite graphs and universality\nThe set of vertices in a graph is usually taken to be finite, but there is no reason we can’t consider graphs to have infinite sets of vertices. In this note in particular, we will consider graphs whose sets of vertices are the natural numbers \\(\\mathbb{N}\\).\n\nDefinition. A graph \\(G\\) with \\(\\operatorname{Vertices}(G)=\\mathbb{N}\\) is said to be universal if, for every pair of finite disjoint subsets \\(S,T\\subseteq\\mathbb{N}\\) there exists a choice of vertex \\(a\\in\\mathbb{N}\\setminus(S\\cup T)\\) that is adjacent to every vertex in \\(S\\) and not adjacent to every vertex in \\(T\\).\n\nSymbolically, a graph \\(G\\) is universal if the following statement holds:\n\\[\n\\forall n,k\\in \\mathbb{N},\\,\\forall S\\in\\binom{\\mathbb{N}}{n},\\,\\forall T\\in\\binom{\\mathbb{N}\\setminus S}{k},\\, \\exists a\\in \\mathbb{N}\\setminus(S\\cup T), \\,\\forall s\\in S\\cup T, \\bigg(s\\in S \\iff \\lbrace a,s\\rbrace \\in\\operatorname{Edges}(G)\\bigg)\n\\]\nFascinatingly, it turns out that all universal graphs are isomorphic!\n\nProposition. All universal graphs on \\(\\mathbb{N}\\) are isomorphic.\n\nProof. Suppose \\(G\\) and \\(H\\) are universal graphs on the natural numbers. Define a sequence of finite subsets \\(A_1,A_2,\\dots\\) of \\(\\mathbb{N}\\) and functions \\(f_1,f_2,\\dots\\), where\n\\[\nf_n:A_n\\to\\mathbb{N}\n\\]\nfor each \\(n\\in\\mathbb{N}\\) recursively as follows.\nDefine \\(A_1=\\lbrace 1\\rbrace\\) and \\(f_1(1)=1\\). Note that \\(f_1\\) is injective and trivially satisfies the relations \\(\\lbrace 1\\rbrace \\subseteq A_1\\) and \\(\\lbrace 1\\rbrace \\subseteq f_1(A_1)\\).\nGiven a number \\(n\\in\\mathbb{N}\\), suppose we have defined \\(A_n\\) and \\(f_n\\) such that \\(f_n\\) is injective and satisfies the properties that\n\\[\n\\lbrace 1,2,\\dots n\\rbrace \\subseteq A_n \\quad\\text{and}\\quad \\lbrace 1,2,\\dots n\\rbrace \\subseteq f_n(A_n).\n\\]\nConsider two cases concerning whether \\(n+1\\in f_n(A_n)\\). - Suppose that \\(n+1\\in f_n(A_n)\\). In this case, let \\(a\\in A_n\\) such that \\(f_n(a)=n+1\\). - Conversely, if \\(n+1\\notin f_n(A_n)\\), by universality of \\(G\\), there exists a choice of vertex \\(a\\in\\mathbb{N}\\setminus A_n\\) such that, for all \\(s\\in A_n\\), the equivalence\n\\[\n\\lbrace  a,s\\rbrace \\in \\operatorname{Edges}(G) \\iff \\lbrace n+1,f_n(s)\\rbrace \\in\\operatorname{Edges}(H)\n\\]\nholds.\nSimilarly, consider the following cases: - If \\(n+1\\in A_n\\), let \\(b=f_n(n+1)\\). - If \\(a=n+1\\), where \\(a\\) is the number chosen above, also let \\(b=n+1\\). - Otherwise, analogous to the step above, by universality of \\(H\\) there exists a choice of vertex \\(b\\in\\mathbb{N}\\setminus f_n(A_n)\\) such that, for all \\(s\\in A_n\\), the equivalence\n\\[\n\\lbrace n+1,s\\rbrace \\in \\operatorname{Edges}(G) \\iff \\lbrace b,f_n(s)\\rbrace \\in\\operatorname{Edges}(H)\n\\]\nholds.\nRegardless of which of the cases above were used, define\n\\[\nA_{n+1} = A_n\\cup\\lbrace n+1, a\\rbrace\n\\]\nand \\(f_{n+1}:A_{n+1}\\to\\mathbb{N}\\) as \\(f_{n+1}(s)= f_n(s)\\) for every $sA_nn+1,a$, and\n\\[\nf_{n+1}(n+1) = b \\quad\\text{and}\\quad f_{n+1}(a) = n+1.\n\\]\nIt is evident that \\(f_{n+1}\\) is injective, and that \\(\\lbrace 1,\\dots,n+1\\rbrace \\subseteq A_{n+1}\\cap f_{n+1}(A_{n+1})\\).\nWith the subsets \\(A_1,A_2,\\dots\\) and functions \\(f_1,f_2,\\dots\\) defined this way, note that we have the chain of inclusions\n\\[\nA_1\\subseteq A_2\\subseteq \\cdots.\n\\]\nMoreover, for every \\(n\\in\\mathbb{N}\\), it holds that \\(f_{n+1}\\|_{A_n} = f_n\\) and for pair of distinct numbers \\(a,b\\in A_n\\) we have the equivalence\n\\[\n\\lbrace a,b\\rbrace \\in \\operatorname{Edges}(G) \\iff \\lbrace f_n(a),f_n(b)\\rbrace \\in \\operatorname{Edges}(H).\n\\]\nWe may now define the desired graph isomorphism \\(f:\\mathbb{N}\\to\\mathbb{N}\\) as\n\\[\nf(n) = f_n(n)\n\\]\nfor every \\(n\\in\\mathbb{N}\\). \\(\\square\\)"
  },
  {
    "objectID": "blog/posts/2023-01-03-random-infinite-graphs.html#random-infinite-graphs-are-almost-always-the-same",
    "href": "blog/posts/2023-01-03-random-infinite-graphs.html#random-infinite-graphs-are-almost-always-the-same",
    "title": "Random Infinite Graphs",
    "section": "Random infinite graphs are almost always the same",
    "text": "Random infinite graphs are almost always the same\nWe now get to the main point of this post: random infinite graphs.\nWe can randomly construct a graph on a set of vertices as follows. Given a set of vertices \\(V\\), for each pair of distinct vertices in \\(V\\), a biased coin is flipped with a probability of \\(p\\) of landing on heads. If the coin lands on heads, an edge is created between those two vertices. This process is repeated for all pairs of distinct vertices in \\(V\\), and the events of whether an edge is created between two vertices are independent of one another. Essentially, the graph is constructed by randomly deciding, with a certain probability, whether or not to add an edge between each pair of distinct vertices.\nThis process induces a probability measure on the set \\(\\operatorname{Graph}(V)\\) of all graphs having vertex set \\(V\\), which is\n\\[\n\\operatorname{Graph}(V) = \\mathcal{P}\\left(\\binom{V}{2}\\right),\n\\]\nwhere \\(\\mathcal{P}(S)\\) denotes the power set of a set \\(S\\). For each pair of distinct elements \\(a,b\\in V\\), define\n\\[\nA_{\\lbrace a,b\\rbrace } = \\big\\lbrace G\\in \\operatorname{Graph}(V)\\,:\\, \\lbrace a,b\\rbrace \\in\\operatorname{Edges}(G)\\big\\rbrace\n\\]\nto be the event that the randomly generated graph contains the edge connecting \\(a\\) and \\(b\\) such that\n\\[\n\\operatorname{Pr}\\big(\\lbrace a,b\\rbrace \\in\\operatorname{Edges}(G)\\big) = \\operatorname{Pr}(A_{\\lbrace a,b\\rbrace }) = p,\n\\]\nand these events are all independent of each other.\nWe now turn our attention to infinite graphs. It turns out that random graphs constructed this way are almost always all isomorphic to each other. This is because a graph constructed this way is almost always universal!\n\nTheorem. Let \\(G\\) be a random graph with \\(\\operatorname{Vertices}(G)=\\mathbb{N}\\) constructed as above. The ranom graph \\(G\\) is universal with probability \\(1\\).\n\nProof. We prove that the set of graphs that are not universal is a set of measure zero. Given disjoint finite sets \\(S,T\\subseteq\\mathbb{N}\\) and a number \\(a\\in\\mathbb{N}\\setminus (S\\cup T)\\), let \\(A(S,T,a)\\) denote the event that in the graph \\(G\\), the vertex \\(a\\) is adjacent to every vertex in \\(S\\) and not adjacent to every vertex in \\(T\\). That is,\n\\[\nA(S,T,a) = \\Bigg(\\bigcup_{s\\in S} A_{\\lbrace a,t\\rbrace }\\Bigg)\\cup\\Bigg(\\bigcup_{t\\in T} (A_{\\lbrace a,t\\rbrace })^c\\Bigg).\n\\]\nNote that the probability of this event is given by\n\\[\n\\operatorname{Pr}\\big(A(S,T,a)\\big) = p^{|S|}(1-p)^{|T|}.\n\\]\nGiven finite disjoint subsets \\(S,T\\subseteq\\mathbb{N}\\) that are not both nonempty, note that the events \\(A(S,T,a)\\) and \\(A(S,T,b)\\) are independent from one another for each choice of \\(a,b\\in\\mathbb{N}\\setminus (S\\cup T)\\) and thus\n\\[\n\\begin{align*}\n\\operatorname{Pr}\\Bigg(\\bigcap_{a\\in\\mathbb{N}\\setminus(S\\cup T)}A(S,T,a)^c\\Bigg)\n&= \\prod_{a\\in\\mathbb{N}\\setminus(S\\cup T)}\\left(1-p^{|S|}(1-p)^{|T|}\\right)\\\\\n&=\\lim_{k\\to\\infty}\\left(1-p^{|S|}(1-p)^{|T|}\\right)^k\\\\\n& =0,\n\\end{align*}\n\\]\nas $0 p{S}(1-p){T} $. Now, the event that the random graph is not universal is\n\\[\n\\bigcup_{n\\in\\mathbb{N}}\\bigcup_{S\\in\\binom{\\mathbb{N}}{k}}\\bigcup_{n\\in\\mathbb{N}}\\bigcup_{T\\in\\binom{\\mathbb{N}\\setminus S}{k}}\\Bigg(\\bigcap_{a\\in\\mathbb{N}\\setminus(S\\cup T)}A(S,T,a)^c\\Bigg),\n\\]\nwhich is a countable union of a measure-zero sets, and thus also has zero measure. \\(\\square\\)\nWe conclude that there is a graph \\(H\\) on \\(\\mathbb{N}\\) such that a randomly generated graph \\(G\\) is almost always isomorphic to \\(H\\).\n\nCorollary. With probability one, random graphs on \\(\\mathbb{N}\\) are all isomorphic to one another."
  },
  {
    "objectID": "blog/posts/2023-01-27-riddler-five-letter-game.html",
    "href": "blog/posts/2023-01-27-riddler-five-letter-game.html",
    "title": "Riddler: Tackling the blind letter challenge — Can You Defeat The TikTok Meme?",
    "section": "",
    "text": "My solution to this week’s riddler. (See more of my Riddler solutions here.)"
  },
  {
    "objectID": "blog/posts/2023-01-27-riddler-five-letter-game.html#riddler-classic",
    "href": "blog/posts/2023-01-27-riddler-five-letter-game.html#riddler-classic",
    "title": "Riddler: Tackling the blind letter challenge — Can You Defeat The TikTok Meme?",
    "section": "Riddler Classic",
    "text": "Riddler Classic\nFrom Angela Zhou comes a challenging meme analysis:\n\nThe #blindletterchallenge has recently taken TikTok by storm. In this challenge, you are presented with five letters, one at a time. Letters are picked randomly, but you can assume that no two letters are the same (i.e., letters are picked without replacement). As each letter is presented, you must identify which of five slots you will place it. The goal is for the letters in all five slots to be in alphabetical order at the end.\nFor example, consider an attempt at the challenge by Michael DiCostanzo. The first letter is X. Since this occurs relatively late in the alphabet, he puts this in the fifth slot. The second letter is U. He puts that in the fourth slot, since it also comes relatively late (and the fifth slot is already occupied). Next, the third letter is E. He takes a gamble, and places E in the first slot. The fourth letter is D. Since D comes before E alphabetically, but no slots prior to E are now available, Michael loses this attempt.\nIf you play with an optimal strategy, always placing letters in slots to maximize your chances of victory, what is your probability of winning?"
  },
  {
    "objectID": "blog/posts/2023-01-27-riddler-five-letter-game.html#solution",
    "href": "blog/posts/2023-01-27-riddler-five-letter-game.html#solution",
    "title": "Riddler: Tackling the blind letter challenge — Can You Defeat The TikTok Meme?",
    "section": "Solution",
    "text": "Solution\nTo get a sense of how to solve this problem more generally, let’s look at an example of this game and see how we might recursively develop a strategy to find the optimal probability of winning. Suppose the first letter we are given is s, which we decide to place in the in the 4th slot.\n\\[\n\\underline{\\quad} \\text{ }\\underline{\\quad} \\text{ } \\underline{\\quad} \\text{ } \\underline{\\text{ }s\\text{ }} \\text{ } \\underline{\\quad}\n\\]\nAfter this placement, we can only win if exactly three of the remaining letters drawn are in the range from a to r (18 letters) and exactly one is in the range from t to z (6 letters). Given that 4 more letters total must be selected out of the remaining 25 letters, the odds of us having a chance of not losing are\n\\[\n\\frac{\\binom{18}{3}\\binom{6}{1}}{\\binom{25}{4}}\n\\]\nbecause, out of the \\(\\binom{25}{4}\\) ways that the remaining 4 letters can be chosen, we can only win if 3 of the letters come from the first 18 letters of the alphabet and the remaining 1 letter is chosen from the final 6 letters. Supposing that we do get lucky enough to get this kind of combination for the remaining letters, what is the best probability of winning at the end? It turns out that we can view the remaining game as two separate similarly structured sub-games!\nIf the original game can be described as “place 5 randomly chosen letters from an alphabet of size 26 into 5 slots in order”, then if we are guaranteed to get three more letters from the first 17 letters and one more letter from the final 6, the remaining game (after placing the s in the fourth slot) can be described as a combination of the two following sub-games:\n\n“place 3 randomly chosen letters from a 17-letter alphabet into 3 slots” and\n“place 1 randomly chosen letter from a 6-letter alphabet into 1 slot”.\n\nMore generally, suppose we are playing a game in which we are randomly given \\(k\\) letters from an \\(n\\)-letter alphabet that we must place into \\(k\\) slots in order. Each of the \\(n\\) letters has a \\(1/n\\) probability of being the first letter to be selected. Suppose letter \\(j\\in\\lbrace 1,2,\\dots,n\\rbrace\\) is the first letter drawn. If we decide to place this letter \\(j\\) into the \\(i^\\text{th}\\) slot (where \\(i\\in\\lbrace 1,2,\\dots,k\\rbrace\\)), the probability that of the remaining (\\(k-1\\)) letters, there are \\((i-1)\\) chosen from the first \\((j-1)\\) letters and \\((k-i)\\) letters chosen from the remaining \\((n-j)\\) letters is\n\\[\n\\frac{\\binom{j-1}{i-1}\\binom{n-j}{k-i}}{\\binom{n-1}{k-1}}.\n\\]\nIf this does not happen, we are guaranteed to lose, but if that does happen, we are effectively left with with two separate games: one where we must place \\((i-1)\\) randomly chosen letters from the first \\((j-1)\\) letters of the alphabet, and another where we must place \\((k-i)\\) randomly chosen letters from the last \\((n-j)\\) letters of the alphabet. To find the optimal odds of winning, we have to maximize over all possible choices \\(i\\in\\lbrace 1,2,\\dots, k\\rbrace\\) of where to place letter \\(j\\). Finally, to compute the optimal odds of winning the whole game, we add up the optimal probabilities of winning in each of the \\(n\\) different cases for the first letter \\(j\\in\\lbrace 1,2,\\dots, n\\rbrace\\).\nIf we let \\(p(n,k)\\) denote the optimal probability of winning a game with an \\(n\\)-letter alphabet where we must place \\(k\\) letters, we have\n\\[\np(n,k) = \\frac{1}{n}\\sum_{j=1}^n \\max\\Bigg\\lbrace \\frac{\\binom{j-1}{i-1}\\binom{n-j}{k-i}}{\\binom{n-1}{k-1}}p(j-1,i-1)p(n-j, k-i)\\quad:\\quad i\\in\\lbrace 1,\\dots,k\\rbrace \\Bigg\\rbrace .\n\\]\nLet’s note a few edge cases. If there are no letters left to place (i.e., \\(k=0\\)) then we win by default, and thus \\(p(n,0)=1\\) for every \\(n\\in\\mathbb{N}\\). Moreover, if the number of slots remaining is exactly equal to the size of the alphabet we pick from, then we can win simply by placing each letter as it appears in its ordered slot, and thus \\(p(n,n)=1\\).\nIt’s now pretty straightforward to write a recursive program (using memoization to reduce computation time) to compute the optimal winning probabilities for different sized games.\nfrom  scipy.special import binom\nfrom functools import cache\n\n@cache\ndef q(n, k, j, i):\n    return binom(j,i) * binom(n-j-1, k-i-1) / binom(n-1,k-1)\n\n@cache\ndef p(n, k):\n    if k &lt;= 1 or n &lt;= k:\n        return 1\n\n    out = (\n        sum(\n            max(q(n, k, j, i) * p(j, i) * p(n-j-1, k-i-1) for i in range(k))\n            for j in range(n)\n        ) / n\n    )\n    return out\nThe standard English alphabet has 26 letters, and computing the result we find that\n\\[\np(26, 5) \\approx 0.254335\n\\]\nHence playing optimally gives us approximately 25.4% chance of winning a game (although this result doesn’t tell us anything about what the strategy is…).\nThe following plot shows how the maximal probability of winning changes for different sizes of alphabet and different numbers of slots, outside of the standard 26-letter alphabet game with 5 slots (up to 75 letters and 75 slots). (The heat map uses a logarithmic scale, otherwise it wouldn’t show much. )\n\n\n\nOptimal probability f winning different games"
  },
  {
    "objectID": "blog/posts/2023-01-27-riddler-five-letter-game.html#the-blind-continuum-challenge",
    "href": "blog/posts/2023-01-27-riddler-five-letter-game.html#the-blind-continuum-challenge",
    "title": "Riddler: Tackling the blind letter challenge — Can You Defeat The TikTok Meme?",
    "section": "The Blind Continuum Challenge",
    "text": "The Blind Continuum Challenge\nWhat happens when the size of the alphabet gets infinitely large, but we keep the number of slots fixed at 5? The probability of winning in this large-alphabet game appears to level off at around 0.22. The following plot shows the optimal probability of winning the 5-letter challenge with different sizes of alphabets.\n\n\n\nOptimal probability f winning different games\n\n\nIndeed, with a 1,000-letter alphabet, we have:\n`p(1000, 5) = 0.222138.`\nIn the limit as \\(n\\to\\infty\\), this game approaches what I’m calling “The Blind Continuum Challenge”. That is, the “letters” are picked uniformly at random from the unit interval. This game can be described as follows.\nSuppose you are given 5 independent and uniformly distributed random numbers on the interval from 0 to 1. Similar to the 5 letter challenge, you must try to place them in order into 5 slots as they appear. What are your optimal odds of winning?\nUsing similar arguments as above in the finite-alphabet game, we arrive at the following recursive expression for \\(p(k)\\), the optimal probability of winning the continuous \\(k\\)-letter challenge:\n\\[\np(k) = \\int_0^1 \\max_{i\\in\\lbrace 1,\\dots,k\\rbrace } \\Bigg(\\binom{k-1}{i-1}x^{i-1}(1-x)^{k-i}p(i-1)p(k-i)\\Bigg)\\mathrm{d}x\n\\]\nI’ve worked out the first few exact values of this probability, all the way up to the blind continuum challenge with 5 “letters”.\n\n\n\n\n\n\n\n\n\\(k\\)\n\\(p(k)\\)\n\n\n\n\n\n1\n1\n\n\n\n2\n\\(\\frac{3}{4}\\)\n\n\n\n3\n\\(\\frac{377}{726}\\)\n≈0.519284\n\n\n4\n\\(\\frac{1037891564126671}{3020778029791104}\\)\n≈0.343584\n\n\n5\n\\(\\frac{300437410741595765908031780282088610389625054477278441195747716452053155421581064323185688795147}{1356952251391926002664799322274919178558749179143258568252348272194427343469119954161606283821760}\\)\n≈0.221406\n\n\n\nIndeed, it seems that the continuous version of this game has an optimal winning probability of around 22.14%."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mark Girard",
    "section": "",
    "text": "I’m a Quantum Algorithm Developer at Photonic Inc. (a quantum computing start-up), where I employ my mathematical expertise to optimize and benchmark implementations of quantum algorithms on Photonic’s quantum stack.\nI live in beautiful Port Moody, BC, with my family.\nI enjoy mathematical puzzles and challenges! Sometimes I like to solve 538’s Riddlers and started compiling my solutions here, or ponder mathematical musings on my blog.\nOutside of mathematics, I enjoy playing ultimate frisbee, homebrewing beer, tabletop games, and various outdoor activities (hiking, camping, climbing, skiing, snowshoeing).\n\n\nWhen I was still in academia, my research interests centred around solving mathematical problems motivated by questions in quantum information theory. I primarily made use of convex analysis, convex optimization, linear algebra, matrix analysis, and operator algebras to tackle questions related to the theory of quantum entanglement.\n\n\n\nB.Sc. in Math/Physics – Trinity University, San Antonio, TX\nDiplom in Physics – Universität Freiburg, Germany\nPh.D. in Applied Mathematics – University of Calgary, Alberta, Canada\nPostdoc & Instructor – Institute for Quantum Computing, University of Waterloo, Ontario, Canada"
  },
  {
    "objectID": "index.html#academic-background",
    "href": "index.html#academic-background",
    "title": "Mark Girard",
    "section": "",
    "text": "When I was still in academia, my research interests centred around solving mathematical problems motivated by questions in quantum information theory. I primarily made use of convex analysis, convex optimization, linear algebra, matrix analysis, and operator algebras to tackle questions related to the theory of quantum entanglement.\n\n\n\nB.Sc. in Math/Physics – Trinity University, San Antonio, TX\nDiplom in Physics – Universität Freiburg, Germany\nPh.D. in Applied Mathematics – University of Calgary, Alberta, Canada\nPostdoc & Instructor – Institute for Quantum Computing, University of Waterloo, Ontario, Canada"
  }
]